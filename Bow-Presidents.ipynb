{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données reconnaissance du locuteur (Chirac/Mitterrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        # \n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./datasets/corpus.tache1.learn.utf8.txt\"\n",
    "alltxts,alllabs = load_pres(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8738 8738\n",
      " Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n",
      "1\n",
      " On est venu ici, non pas pour donner le moindre conseil superflu mais on a évoqué en terminant deux problèmes sur lesquels je voudrais mettre l'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(alltxts),len(alllabs))\n",
    "print(alltxts[0])\n",
    "print(alllabs[0])\n",
    "print(alltxts[-1])\n",
    "print(alllabs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\\n\",\n",
       " \" D'abord merci de cet exceptionnel accueil que les Congolais, les Brazavillois, nous ont réservé cet après-midi.\\n\",\n",
       " \" C'est toujours très émouvant de venir en Afrique car c'est probablement l'une des rares terres du monde où l'on ait conservé cette convivialité, cette amitié, ce respect de l'autre qui s'expriment avec chaleur, avec spontanéité et qui réchauffent le coeur de ceux qui arrivent et de ceux qui reçoivent.\\n\",\n",
       " ' Aucun citoyen français ne peut être indifférent à un séjour à Brazzaville.\\n',\n",
       " ' Le Congo, que naguère le <nom> qualifia de \"refuge pour la liberté\", de \"base de départ pour la libération\", de \"môle pour la Résistance\", comment ne pas être heureux de s\\'y retrouver ?\\n',\n",
       " ' Comment ne pas y voir un signe ?\\n',\n",
       " \" Brazzaville n'est pas une capitale ordinaire.\\n\",\n",
       " ' Les voies de la libre disposition des peuples et de leur coopération furent explorées il y a un demi siècle, ici, à Brazzaville.\\n',\n",
       " \" C'est à Brazzaville, encore, que quinze années plus tard fut proclamée la Communauté.\\n\",\n",
       " ' A Brazzaville, que fut scellée la première union régionale des pays africains francophones.\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltxts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '100', '1000', '10000', '100000', '101e', '11', '110', '1100', '12', '120', '1200', '1244', '1295', '13', '14', '141', '142', '1441', '15', '150', '150ème', '16', '160', '16000', '17', '170', '1782', '1789', '1792', '1798', '18', '1848', '185', '1860', '1870', '19', '19ème', '1er', '1h28', '1ère', '20', '200', '200000', '20ème', '21', '22', '22000', '23', '2300000', '23600', '24', '242', '25', '250', '26', '260', '27', '28', '29', '2h15', '2ème', '30', '300', '3000', '30000', '31', '32', '320', '338', '340', '35', '350', '36', '38', '3ème', '3èmes', '40', '400', '400000', '40ème', '4200', '43', '44', '45', '48', '49', '4e', '4ème', '50', '500', '5000', '500000', '51', '52', '55', '550', '60', '600', '61', '63', '64', '6ème', '70', '700', '700000', '75', '80', '800', '81', '82e', '85', '86', '89', '90', '900000', '918', '94', '95', '99', '9ème', 'aaron', 'abaissement', 'abaissent', 'abandon', 'abandonne', 'abandonnent', 'abandonner', 'abandonné', 'abandonnée', 'abandonnées', 'abattait', 'abattent', 'abattre', 'abattu', 'abidjan', 'abm', 'abolir', 'abolirait', 'abolit', 'abolition', 'abominables', 'abondante', 'abord', 'aborde', 'aborder', 'abordera', 'aborderai', 'aborderons', 'abordions', 'abordé', 'abordée', 'abordés', 'abouti', 'aboutir', 'aboutissait', 'aboutisse', 'aboutissement', 'aboutissent', 'aboutit', 'abraham', 'abreuver', 'abri', 'abritant', 'abrite', 'abritent', 'abrogation', 'absence', 'absolue', 'absolument', 'absolus', 'absorbe', 'absorber', 'abstraite', 'abstraits', 'absurde', 'absurdes', 'absurdité', 'abus', 'abuser', 'abusivement', 'abîmer', 'abîmes', 'abîmée', 'académicien', 'académie', 'acapulco', 'accaparement', 'accent', 'accentue', 'accentuer', 'acceptable', 'acceptaient', 'acceptant', 'acceptation', 'accepte', 'acceptent', 'accepter', 'accepterai', 'accepteraient', 'accepterait', 'accepterions', 'accepterons', 'accepté', 'acceptée', 'acceptées', 'acceptés', 'accessibilité', 'accessible', 'accession', 'accessoire', 'accident', 'accidents', 'acclame', 'accolés', 'accompagnait', 'accompagnant', 'accompagnateurs', 'accompagne', 'accompagnement', 'accompagnent', 'accompagner', 'accompagnera', 'accompagnons', 'accompagné', 'accompagnées', 'accompagnés', 'accompli', 'accomplie', 'accomplies', 'accomplir', 'accomplirent', 'accomplis', 'accomplisse', 'accomplissement', 'accomplissent', 'accomplissions', 'accomplit', 'accord', 'accordant', 'accorde', 'accordent', 'accorder', 'accordera', 'accordez', 'accords', 'accordé', 'accordée', 'accordées', 'accroche', 'accroissaient', 'accroissement', 'accroissent', 'accroît', 'accroître', 'accru', 'accrue', 'accrues', 'accrus', 'accréditer', 'accueil', 'accueillaient', 'accueillait', 'accueillant', 'accueillante', 'accueillantes', 'accueille', 'accueillera', 'accueillerez', 'accueilli', 'accueillie', 'accueillies', 'accueillir', 'accueillis', 'accueillons', 'accumulation', 'accumuler', 'accumulé', 'accumulée', 'accumulées', 'accumulés', 'accusateurs', 'accède', 'accèdent', 'accès', 'accédant', 'accédants', 'accéder', 'accédé', 'accélère', 'accélèrent', 'accélérateur', 'accélération', 'accélérer', 'accéléré', 'accélérée', 'acharne', 'acharnement', 'acharnent', 'acharné', 'achat', 'achats', 'achemine', 'acheter', 'achetez', 'achever', 'achevé', 'achevée', 'achevées', 'achète', 'achève', 'achèvement', 'achèvent', 'achèvera', 'acquerrons', 'acquierent', 'acquis', 'acquise', 'acquises', 'acquisition', 'acquièrent', 'acquérant', 'acquérir', 'act', 'acte', 'actes', 'acteur', 'acteurs', 'actif', 'actifs', 'action', 'actionnaires', 'actions', 'active', 'activement', 'actives', 'activité', 'activités', 'actualisation', 'actualité', 'actuel', 'actuelle', 'actuellement', 'actuelles', 'actuels', 'acuité', 'ad', 'adam', 'adaptant', 'adaptation', 'adaptations', 'adapte', 'adaptent', 'adapter', 'adaption', 'adapté', 'adaptée', 'adaptées', 'adaptés', 'addition', 'additionner', 'aden', 'adenauer', 'adhère', 'adhèrent', 'adhérents', 'adhérer', 'adhéré', 'adhésion', 'adieu', 'admets', 'admette', 'admettre', 'administratif', 'administration', 'administrations', 'administrative', 'administratives', 'admirable', 'admirablement', 'admirables', 'admiratif', 'admiration', 'admire', 'admirer', 'admirons', 'admiré', 'admirée', 'admis', 'admissible', 'adolescence', 'adolescent', 'adolescents', 'adoptant', 'adopte', 'adopter', 'adoption', 'adoptèrent', 'adopté', 'adoptée', 'adoptées', 'adosse', 'adossé', 'adossée', 'adption', 'adressaient', 'adressait', 'adressant', 'adresse', 'adressent', 'adresser', 'adresserez', 'adressé', 'adressés', 'adulte', 'adultes', 'adversaire', 'adversaires', 'adverses', 'adéquation', 'affable', 'affaibli', 'affaiblir', 'affaiblissent', 'affaire', 'affaires', 'affaissent', 'affectait', 'affecte', 'affectif', 'affection', 'affections', 'affective', 'affectueux', 'affectée', 'affectées', 'affectés', 'affermie', 'affichent', 'afficher', 'affine', 'affinité', 'affinités', 'affirmait', 'affirmant', 'affirmation', 'affirme', 'affirment', 'affirmer', 'affirmera', 'affirmons', 'affirmé', 'affirmée', 'affluents', 'affranchi', 'affranchie', 'affranchir', 'affrontement', 'affrontements', 'affrontent', 'affronter', 'affrontés', 'affréteur', 'affréteurs', 'affrétez', 'affût', 'afghanistan', 'afin', 'africain', 'africaine', 'africaines', 'africains', 'afrika', 'afrique', 'agacent', 'agadir', 'age', 'agence', 'agences', 'agenda', 'agent', 'agents', 'agglomération', 'aggravant', 'aggravation', 'aggrave', 'aggravent', 'aggraver', 'agi', 'agir', 'agira', 'agirait', 'agissait', 'agissant', 'agissante', 'agisse', 'agissent', 'agissions', 'agissons']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus, classes = alltxts,alllabs\n",
    "\n",
    "# vectorizer = CountVectorizer(input='content', encoding='utf-8',\n",
    "#                              decode_error='strict', strip_accents=None,\n",
    "#                              lowercase=True, preprocessor=None, tokenizer=None,\n",
    "#                              stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b',\n",
    "#                              ngram_range=(1, 1), analyzer='word',\n",
    "#                              max_df=1.0, min_df=1, max_features=None,\n",
    "#                              vocabulary=None, binary=False, dtype='numpy.int64')\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names()[:500]) # we only print a few\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Transformation paramétrique du texte (pre-traitements)\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots entièrement en majuscule en marqueurs spécifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la première ligne = titre, seulement la dernière ligne = résumé, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "Vérifier systématiquement sur un exemple ou deux le bon fonctionnement des méthodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "import io\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "reg = \"\\b[^\\W]\\b\" #matches word with characters \n",
    "\n",
    "# 1) Try removing punctuation or putting text to lower case (maybe use a regex)\n",
    "# 2) Try \"Stemming\" - \"pos-tagging\" the text\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Transforms text to remove unwanted bits.\n",
    "    \"\"\"\n",
    "    # replace url by a keywork URL\n",
    "    text = re.sub('(www|http)[\\w\\.-_]+\\.(fr|com|org)', 'URL', text)  # note: this regex is far from perfect\n",
    "    # remove numbers\n",
    "    text = re.sub('[0-9]+', '', text) # remplacer une séquence de chiffres par rien   \n",
    "    # remove punctuation\n",
    "    punc = string.punctuation  \n",
    "    punc += '\\n\\r\\t'\n",
    "    text = text.translate(str.maketrans(punc, ' ' * len(punc)))  \n",
    "    # remove accents\n",
    "    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "    # remove uppercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text.replace(\".\",\" \") # This function is only taking care of dots, what about !:,?+-&*%\n",
    "\n",
    "vectorizer = CountVectorizer(preprocessor=preprocess)\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Dictionary processing**: If we visualize the word frequency distribution we see that a few words (roughly 20) appear a lot more than the others. These words are often refered to as **stop words**. Would remove them improve accuracy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 10198), ('', 8738), ('la', 6079), ('et', 5293), ('à', 3954), ('le', 3859), ('les', 3619), ('des', 3168), ('que', 2489), ('qui', 2324), ('en', 2188), ('pour', 1733), ('dans', 1670), ('du', 1634), ('un', 1397), ('une', 1340), ('nous', 1219), ('au', 1096), ('plus', 1094), ('vous', 1084)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ1klEQVR4nO3df4xd5Z3f8ffn3Ds/PGZtj43rGNvEZuNk41DtwrrGlCiKAgHDZtdUSiJQVCzqrluV7rJJpBRaVVaTTZtIq7DQblDc4F1IIwhlo2KxNMh1yNK0gTCEiN/gAQK2a+MBGwM29vz69o/z3Dt37p1h7Lkzc+05n5c0uuc85znnPmeO4TPPc34pIjAzs2LLWt0AMzNrPYeBmZk5DMzMzGFgZmY4DMzMDCi3ugGTdfbZZ8fKlStb3QwzszPGE0888WZELB5r2RkbBitXrqSnp6fVzTAzO2NIem28ZR4mMjMzh4GZmTkMzMwMh4GZmeEwMDMzHAZmZobDwMzMKGAY3LZrN3//Ul+rm2FmdlopXBjc/rOX+fluh4GZWa0Jw0DSdkkHJT1TU7ZQ0k5Ju9NndyqXpNsk9Up6StKFNetsSvV3S9pUU/77kp5O69wmSVO9k7VKmRj2+3zMzEY5mZ7B3wAb6spuAnZFxGpgV5oHuBJYnX62ALdDHh7AVuAiYB2wtRIgqc4f16xX/11TSoIhp4GZ2SgThkFEPAIcqiveCNyZpu8Erq4pvytyjwILJC0FrgB2RsShiDgM7AQ2pGXzIuLRyN+/eVfNtqZF3jNwGJiZ1ZrsOYMlEbE/TR8AlqTpZcCemnp7U9kHle8do3xMkrZI6pHU09c3uXH/kuSegZlZnaZPIKe/6Gfk/64RsS0i1kbE2sWLx3wK64QynzMwM2sw2TB4Iw3xkD4PpvJ9wIqaestT2QeVLx+jfNpkgmGngZnZKJMNgx1A5YqgTcD9NeXXpauK1gNH0nDSQ8DlkrrTiePLgYfSsnckrU9XEV1Xs61pUZIY8jkDM7NRJny5jaS7gU8DZ0vaS35V0LeAeyVtBl4DvpiqPwhcBfQCx4DrASLikKRvAI+nel+PiMpJ6X9FfsXSHOB/pp9pk2Vyz8DMrM6EYRAR146z6NIx6gZwwzjb2Q5sH6O8Bzh/onZMFV9NZGbWqHB3IGcSQ84CM7NRChgGPoFsZlavcGFQynyfgZlZvcKFQSafMzAzq+cwMDOz4oWBh4nMzBoVLgyyzFcTmZnVK1wYlAThYSIzs1EKFwaZn1pqZtageGHgcwZmZg0KFwYlX01kZtageGHg9xmYmTUoXBj4HchmZo0KFwZ+aqmZWaPihYGvJjIza1C4MPA7kM3MGhUvDPwIazOzBoULg1LmdyCbmdUrXBhk8juQzczqFTIMHAVmZqMVLgwkfGmpmVmdwoVBJuEsMDMbrXBhINwzMDOrV7wwcM/AzKxBAcPAL7cxM6tXuDDIhK8mMjOrU7gwEH5QnZlZvcKFQZbhcwZmZnUKFwbgB9WZmdUrXBhkAp81MDMbrakwkPRlSc9KekbS3ZI6Ja2S9JikXkk/ktSe6nak+d60fGXNdm5O5S9KuqLJfZqgzbhnYGZWZ9JhIGkZ8KfA2og4HygB1wDfBm6JiI8Ah4HNaZXNwOFUfkuqh6Q1ab1PABuA70oqTbZdE8nvQHYamJnVanaYqAzMkVQGuoD9wGeA+9LyO4Gr0/TGNE9afqkkpfJ7IuJERLwK9ALrmmzXuPI7kKdr62ZmZ6ZJh0FE7AP+AnidPASOAE8Ab0fEYKq2F1iWppcBe9K6g6n+otryMdYZRdIWST2Sevr6+ibVbrlnYGbWoJlhom7yv+pXAecAc8mHeaZNRGyLiLURsXbx4sWT2kZ+B/IUN8zM7AzXzDDRZcCrEdEXEQPAj4FLgAVp2AhgObAvTe8DVgCk5fOBt2rLx1hnyvl9BmZmjZoJg9eB9ZK60tj/pcBzwMPA51OdTcD9aXpHmict/2nk4zU7gGvS1UargNXAL5to1wfyU0vNzBqVJ64ytoh4TNJ9wK+AQeBJYBvwd8A9kv48ld2RVrkD+IGkXuAQ+RVERMSzku4lD5JB4IaIGJpsuyaSZX5qqZlZvUmHAUBEbAW21hW/whhXA0XEceAL42znm8A3m2nLyXLPwMysUeHuQJbPGZiZNShgGPh9BmZm9QoXBpkvLTUza1C4MPD7DMzMGhUuDPymMzOzRoULA+RLS83M6hUuDPL3GfgksplZrcKFgcjTwE8uNTMbUbgwcM/AzKxR4cJAKQzcMzAzG1HAMMjTIHxNkZlZVQHDIP/0KJGZ2YjChUFW6Rk4DMzMqgoXBqlj4LuQzcxqFC4Mqj2DFrfDzOx0UrgwGLmayHFgZlZRwDDwOQMzs3rFC4P06ZvOzMxGFC4MMt90ZmbWoHhhkFWGiZwGZmYVhQuDkUtLW9oMM7PTSvHCwI+jMDNrUMAwyD89SmRmNqJwYeDHUZiZNSpcGPhxFGZmjQoXBn4chZlZo8KFQaVrMOzLiczMqgoXBpWegZmZjShcGPicgZlZo8KFQZb22FlgZjaiqTCQtEDSfZJekPS8pIslLZS0U9Lu9Nmd6krSbZJ6JT0l6cKa7WxK9XdL2tTsTn1gm1PfwD0DM7MRzfYMbgV+EhG/A/wu8DxwE7ArIlYDu9I8wJXA6vSzBbgdQNJCYCtwEbAO2FoJkOlQeTaRw8DMbMSkw0DSfOBTwB0AEdEfEW8DG4E7U7U7gavT9Ebgrsg9CiyQtBS4AtgZEYci4jCwE9gw2XZNpJzCYNBXE5mZVTXTM1gF9AF/LelJSd+XNBdYEhH7U50DwJI0vQzYU7P+3lQ2XnkDSVsk9Ujq6evrm1Sj20r5Lg8MOgzMzCqaCYMycCFwe0RcABxlZEgIgMifEz1l/9eNiG0RsTYi1i5evHhS2yiX8p7BwPDwVDXLzOyM10wY7AX2RsRjaf4+8nB4Iw3/kD4PpuX7gBU16y9PZeOVT4u2dDnR4JB7BmZmFZMOg4g4AOyR9LFUdCnwHLADqFwRtAm4P03vAK5LVxWtB46k4aSHgMsldacTx5ensmlR6RkMDrlnYGZWUW5y/T8BfiipHXgFuJ48YO6VtBl4DfhiqvsgcBXQCxxLdYmIQ5K+ATye6n09Ig412a5xtVWHidwzMDOraCoMIuLXwNoxFl06Rt0AbhhnO9uB7c205WSVq8NE7hmYmVUU7g7k6glknzMwM6sqXBhULi0d9NVEZmZVhQuD6k1n7hmYmVUVLgwqPYN+nzMwM6sqbBi4Z2BmNqJwYVC9z8DnDMzMqgoXBpU7kH01kZnZiMKFge9ANjNrVLgwKKWriYb8PgMzs6rChUGm9HIbP47CzKyqcGFQ7Rl4lMjMrKpwYZCywMNEZmY1ChcGksjkYSIzs1qFCwPIh4rcMzAzG1HIMMgk9wzMzGoUMgxKmRhyGJiZVRUzDORhIjOzWoUMgyzzMJGZWa1ChoFPIJuZjVbIMMgk33RmZlajkGFQynyfgZlZrWKGgU8gm5mNUsgw8AlkM7PRChkGPoFsZjZaMcNAvunMzKxWIcMgy8SwewZmZlWFDAP3DMzMRitkGGSZ7zMwM6tVyDAoZXiYyMysRtNhIKkk6UlJD6T5VZIek9Qr6UeS2lN5R5rvTctX1mzj5lT+oqQrmm3TRDxMZGY22lT0DG4Enq+Z/zZwS0R8BDgMbE7lm4HDqfyWVA9Ja4BrgE8AG4DvSipNQbvG5RPIZmajNRUGkpYDfwB8P80L+AxwX6pyJ3B1mt6Y5knLL031NwL3RMSJiHgV6AXWNdOuibhnYGY2WrM9g78EvgZUTscuAt6OiME0vxdYlqaXAXsA0vIjqX61fIx1pkXml9uYmY0y6TCQ9DngYEQ8MYXtmeg7t0jqkdTT19c36e10lDOOD/pyIjOzimZ6BpcAfyTpN8A95MNDtwILJJVTneXAvjS9D1gBkJbPB96qLR9jnVEiYltErI2ItYsXL550wz+8qItX+94jfN7AzAxoIgwi4uaIWB4RK8lPAP80Ir4EPAx8PlXbBNyfpnekedLyn0b+f+MdwDXpaqNVwGrgl5Nt18lYdfZZvHN8kLePDUzn15iZnTGm4z6DfwN8RVIv+TmBO1L5HcCiVP4V4CaAiHgWuBd4DvgJcENEDE1Du6q6u9oAePt9h4GZGUB54ioTi4ifAT9L068wxtVAEXEc+MI4638T+OZUtOVkzJ+Th8E7DgMzM6CgdyDPS2FwxGFgZgYUNAzmOwzMzEYpZBjM7chHx46eGJygpplZMRQyDDrL+W6f8L0GZmZAUcOgLX/00fGBab1oyczsjFHwMHDPwMwMChoGpUy0lcTxQfcMzMygoGEA0FkueZjIzCwpbBh0tJU8TGRmlhQ3DMoZJ9wzMDMDChwGnW2ZzxmYmSWFDYOOcon+QT/C2swMChwGbSUxMORzBmZmUOgwyBwGZmaJw8DMzAocBuWM/iGfMzAzgwKHQXtJDPhBdWZmQIHDwMNEZmYjCh0Gg8MeJjIzg4KHQb+HiczMgAKHQXvZ9xmYmVUUNgx8zsDMbETBw8DnDMzMoMBhUC7J5wzMzJLChsG8zjb6h4Y51j/Y6qaYmbVcYcPgQ/M6AXjjnRMtbomZWesVNwzm52Fw4MjxFrfEzKz1ChsGS+Z1APDGOw4DM7MCh0FlmMhhYGZW2DA4q6NMV3uJAw4DM7PJh4GkFZIelvScpGcl3ZjKF0raKWl3+uxO5ZJ0m6ReSU9JurBmW5tS/d2SNjW/WyfVfuZ1tnH0hK8mMjNrpmcwCHw1ItYA64EbJK0BbgJ2RcRqYFeaB7gSWJ1+tgC3Qx4ewFbgImAdsLUSINOtsy3j+IDvNTAzm3QYRMT+iPhVmn4XeB5YBmwE7kzV7gSuTtMbgbsi9yiwQNJS4ApgZ0QciojDwE5gw2TbdSo6yiWODwzNxFeZmZ3WpuScgaSVwAXAY8CSiNifFh0AlqTpZcCemtX2prLxysf6ni2SeiT19PX1Nd3uzraM474L2cys+TCQdBbwt8CfRcQ7tcsiIoApewBQRGyLiLURsXbx4sVNb6+jrcQJ9wzMzJoLA0lt5EHww4j4cSp+Iw3/kD4PpvJ9wIqa1ZensvHKp11nW8k9AzMzmruaSMAdwPMR8Z2aRTuAyhVBm4D7a8qvS1cVrQeOpOGkh4DLJXWnE8eXp7Jp11nO3DMwMwPKTax7CfBPgacl/TqV/VvgW8C9kjYDrwFfTMseBK4CeoFjwPUAEXFI0jeAx1O9r0fEoSbaddI623wC2cwMmgiDiPg5oHEWXzpG/QBuGGdb24Htk23LZHW1l3j3+CARQd7RMTMrpsLegQyw5px5vHW0n9+8dazVTTEza6lCh8FlH8+ven3w6f0T1DQzm90KHQbnLJjDb3WW6XvX7zQws2IrdBhA/sazd94faHUzzMxaqvBhMH9OG0ccBmZWcA4Dh4GZmcPgnAVzeLnvPYaHp+ypGWZmZ5zCh8FFqxZy+NgArx3y5aVmVlyFD4MPL+oCYI/DwMwKrPBhcG4lDA47DMysuAofBkt+q5P2UsaeQ++3uilmZi1T+DDIMrGsew7bf/4qr/uxFGZWUIUPA4Br160gCL5y769b3RQzs5Zo5hHWs8aWT/02xweG+c7Ol3j7WD8Lutpb3SQzsxnlnkHyj397EQA/+MVrLW6JmdnMcxgkv//hbs5fNo/vPfIKQ74BzcwKxmGQSOKff/I83jsxyAsH3ml1c8zMZpTDoMbald0A/IsfPEHvwfda3Bozs5njMKixvLuLf/+5New9/D4PPPX/Wt0cM7MZ4zCos/mTq/j40nn88LHXOT4w1OrmmJnNCIfBGL624WP0vXuCP/+75zjWP9jq5piZTTuHwRg+/dHFXH/JSv7bo6+z8b/8H/cQzGzWcxiMQRJb//ATfPdLF7L74Htcs+1Rnt57pNXNMjObNg6DD3Dl+R/iy5d9lKf3HeEL3/u/bHvkZZ7Z51Aws9nHYfABJHHjZat5+KufZkV3F//xwRf43H/+Of/1kVc4dLS/1c0zM5syijgz77Zdu3Zt9PT0zNj3RQSvHzrGn9z9JE/tPcLc9hJ//KnzuOzjS/jEOfOQNGNtMTObDElPRMTaMZc5DE5NRPCr1w/znx58gZ7XDgP529IuPLebr3z2o6xY2DXjbTIzOxkOg2my59Ax/v6lPv737j4eeelNhiL4veULuPIffoh/csEyP/3UzE4rDoMZsOfQMe76xW/Y9fxBXnnzKO3ljH+0spsV3V2sWNjFmqXzOHdRF0vnd9LV7ieHm9nMcxjMsF++eogHn97Po6+8Rd+7J3ir7mTzgq42PjSvk+Xdc1je3cU/mNfBorntLJrbwcKz2ll8VgdL53dSLvn8vplNnQ8Kg9PmT1RJG4BbgRLw/Yj4VoubNGnrVi1k3aqF1fn3TgzyzL4jHDhynH1vv8/+I+9z4Mhx9h5+n1+8/BZH+xtvamsriQVd7cxtL9HVXmZuR4m5HWXmtpeZ016iq73E/DltzJ/TRmdbifZyRkc5o72U0dlWyqfLGeVSRjkTbaWMtlLlM6NcEm1Z/lmZzjKfBDcrqtMiDCSVgL8CPgvsBR6XtCMinmtty6bGWR1l1p+3aNzlx/oHeeu9fg4dzX/eeOc4rx06xtvHBjh6YpBj/YMcPTHE4aP97Dl0jGP9QxzrH+Ld4wNM5asXMkE5BUQpy3/KmciUT2fKg6OkFCplUc6yvK5G1slq1itnqm4vU+UHSplQzXQmIUFJ+fqVepVP1aybZXnd2jqq266oX061zljzI5+VZVS3U6kn0rJUVpnOskq9xnWq26Nmu6O2A9Rvt1o+UpeG7Y/eDmm++juguoHqupXZypVvlegf67v4gGUj6zVux1fVnblOizAA1gG9EfEKgKR7gI3ArAiDiXS1l+laWD7lK5GGh4N3jw9yYnCIE4PD9A8Nc2Kg8pmXDQ4PMzAUDA4Fg8PD9A8OMzgc1c/BofxzYGg41RkpG45gaLjmp2Z+YGhkW7X1TgwOMRR52waHg6HhfLtDkdcbHib/jGA41audrq0XpPIIztDRzMI7lRCqhPLIuiMzapgYNTmy7QmWj/X99bXrQ69xuxPVbQzEUeuPsa2x2l35gyOTRm2/u6ude//lxQ3f0azTJQyWAXtq5vcCF9VXkrQF2AJw7rnnzkzLTmNZJuZ3tQFtrW7KtIsUCNXgGDU/EjJDqTwiCBgVNBH1AZNPR8BQNZQq9aguh8p3jWw36qaHq9M13zM88v2VbVTXZfT3UFc+Mj/yPTSsN3qe9F2VN/VFze9u5PeYPom6+fGX1W6jtn5tm8daVin4oG3X/i5r3zBYm/3169a3rb6N460/7r6NWXfs75rMtmrbPdbkeO2u/Xdaa17n9Pz3frqEwUmJiG3ANshPILe4OTaDqn8l0fhXl5k173S5XGUfsKJmfnkqMzOzGXC6hMHjwGpJqyS1A9cAO1rcJjOzwjgthokiYlDSvwYeIr+0dHtEPNviZpmZFcZpEQYAEfEg8GCr22FmVkSnyzCRmZm1kMPAzMwcBmZm5jAwMzPO4KeWSuoDXpvk6mcDb05hc84E3udi8D7Pfs3s74cjYvFYC87YMGiGpJ7xHuM6W3mfi8H7PPtN1/56mMjMzBwGZmZW3DDY1uoGtID3uRi8z7PftOxvIc8ZmJnZaEXtGZiZWQ2HgZmZFSsMJG2Q9KKkXkk3tbo9U0XSCkkPS3pO0rOSbkzlCyXtlLQ7fXanckm6Lf0enpJ0YWv3YPIklSQ9KemBNL9K0mNp336UHomOpI4035uWr2xpwydJ0gJJ90l6QdLzki6e7cdZ0pfTv+tnJN0tqXO2HWdJ2yUdlPRMTdkpH1dJm1L93ZI2nUobChMGkkrAXwFXAmuAayWtaW2rpswg8NWIWAOsB25I+3YTsCsiVgO70jzkv4PV6WcLcPvMN3nK3Ag8XzP/beCWiPgIcBjYnMo3A4dT+S2p3pnoVuAnEfE7wO+S7/usPc6SlgF/CqyNiPPJH3F/DbPvOP8NsKGu7JSOq6SFwFbyVwavA7ZWAuSkRHrH5mz/AS4GHqqZvxm4udXtmqZ9vR/4LPAisDSVLQVeTNPfA66tqV+tdyb9kL8RbxfwGeAB8neJvwmU6485+bsyLk7T5VRPrd6HU9zf+cCr9e2ezceZkfejL0zH7QHgitl4nIGVwDOTPa7AtcD3aspH1ZvopzA9A0b+UVXsTWWzSuoWXwA8BiyJiP1p0QFgSZqeLb+LvwS+Bgyn+UXA2xExmOZr96u6z2n5kVT/TLIK6AP+Og2NfV/SXGbxcY6IfcBfAK8D+8mP2xPM7uNccarHtanjXaQwmPUknQX8LfBnEfFO7bLI/1SYNdcRS/occDAinmh1W2ZQGbgQuD0iLgCOMjJ0AMzK49wNbCQPwnOAuTQOp8x6M3FcixQG+4AVNfPLU9msIKmNPAh+GBE/TsVvSFqali8FDqby2fC7uAT4I0m/Ae4hHyq6FVggqfIGv9r9qu5zWj4feGsmGzwF9gJ7I+KxNH8feTjM5uN8GfBqRPRFxADwY/JjP5uPc8WpHtemjneRwuBxYHW6CqGd/CTUjha3aUpIEnAH8HxEfKdm0Q6gckXBJvJzCZXy69JVCeuBIzXd0TNCRNwcEcsjYiX5sfxpRHwJeBj4fKpWv8+V38XnU/0z6i/oiDgA7JH0sVR0KfAcs/g4kw8PrZfUlf6dV/Z51h7nGqd6XB8CLpfUnXpUl6eyk9PqkyYzfILmKuAl4GXg37W6PVO4X58k70I+Bfw6/VxFPla6C9gN/C9gYaov8iurXgaeJr9So+X70cT+fxp4IE2fB/wS6AX+O9CRyjvTfG9afl6r2z3Jff09oCcd6/8BdM/24wz8B+AF4BngB0DHbDvOwN3k50QGyHuAmydzXIF/lva9F7j+VNrgx1GYmVmhhonMzGwcDgMzM3MYmJmZw8DMzHAYmJkZDgMzM8NhYGZmwP8HV97xi4TNTWMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the count of the 1000 most used words:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "wc = Counter()\n",
    "for text in corpus:\n",
    "    wc.update(text.split(\" \"))\n",
    "    \n",
    "freq = [f for w,f in wc.most_common(1000)]\n",
    "\n",
    "plt.plot(freq[:1000])\n",
    "print(wc.most_common(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's remove stopwords:** english stop words: direclty on sklearn \n",
    "\n",
    "- **stop_words:** string {‘english’}, list, or None (default)\n",
    "    - If ‘english’, a built-in stop word list for English is used. There are several known issues with ‘english’ and you should consider an alternative (see Using stop words).\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if analyzer == 'word'.\n",
    "    - If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms.\n",
    "\n",
    "[see CountVectorizer for full doc](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='french') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build your own list**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8738, 12504)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8738, 12504)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer can take a list of stop words as argument.\n",
    "# Build or download a list of stop word (from NLTK for exemple)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# remove stop words\n",
    "stop_words = list(stopwords.words('french'))\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "print(X.shape)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Dictionary processing, restricting vocabulary size: corpus-specific stopwords** => max_df + suppress rare words (min_df) + max_features \n",
    "\n",
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "- **max_features:** int or None, default=None\n",
    "If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "[see CountVectorizer for full doc](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3484\n"
     ]
    }
   ],
   "source": [
    "# max_df: float (ratio) / integer(number) of document above which we remove the word)\n",
    "# min_df: float (ratio) / integer(number) of document under which we remove the word)\n",
    "\n",
    "min_df=5             \n",
    "max_df=0.5\n",
    "max_features=10000\n",
    "vectorizer = CountVectorizer(max_df=max_df,min_df=min_df,max_features=max_features) #try out some values\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "#What is the dictionnary size now ?\n",
    "dic_size = X.shape[1]###\n",
    "print(dic_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Extraction du vocabulaire (BoW)\n",
    "\n",
    "- **Exploration préliminaire des jeux de données**\n",
    "    - Quelle est la taille d'origine du vocabulaire?\n",
    "    - Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\n",
    "    - Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]\n",
    "    - Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "    - Quelle est la distribution d'apparition des mots (Zipf)\n",
    "    - Quels sont les 100 bigrammes/trigrammes les plus fréquents?\n",
    "\n",
    "- **Variantes de BoW**\n",
    "    - TF-IDF\n",
    "    - Réduire la taille du vocabulaire (min_df, max_df, max_features)\n",
    "    - BoW binaire\n",
    "    - Bi-grams, tri-grams\n",
    "    - **Quelles performances attendrent? Quels sont les avantages et les inconvénients des ces variantes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Métriques d'évaluation \n",
    "\n",
    "Il faudra utiliser des métriques d'évaluation pertinentes suivant la tâche et l'équilibrage des données : \n",
    "- Accuracy\n",
    "- Courbe ROC, AUC, F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Variantes sur les stratégies d'entraînement\n",
    "\n",
    "- **Sur-apprentissage**. Les techniques sur lesquelles nous travaillons étant sujettes au sur-apprentissage: trouver le paramètre de régularisation dans la documentation et optimiser ce paramètre au sens de la métrique qui vous semble la plus appropriée (cf question précédente).\n",
    "\n",
    " <br>\n",
    "- **Equilibrage des données**. Un problème reconnu comme dur dans la communauté est celui de l'équilibrage des classes (*balance* en anglais). Que faire si les données sont à 80, 90 ou 99% dans une des classes?\n",
    "Le problème est dur mais fréquent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. Ré-équilibrer le jeu de données: supprimer des données dans la classe majoritaire et/ou sur-échantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de coût pour pénaliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les écarts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn possèdent des arguments pour régler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les prédictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'à ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associés à cette approche mène directement à la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrinsèquement plus résistante au problème d'équilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Estimer les performances de généralisation d'une méthodes\n",
    "**Ce sera l'enjeu principal du projet : vous disposez d'un ensemble de données, et vous évaluerez les performances sur un ensemble de test auquel vous n'avez pas accès. Il faut donc être capable d'estimer les performances de généralisation du modèles à partir des données d'entraînement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Avant de lancer de grandes expériences, il faut se construire une base de travail solide en étudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps ça prend d'apprendre un classifieur NB/SVM/RegLog sur ces données en fonction de la taille du vocabulaire?\n",
    "- La validation croisée est-elle nécessaire? Est ce qu'on obtient les mêmes résultats avec un simple *split*?\n",
    "- La validation croisée est-elle stable? A partir de combien de fold (travailler avec différentes graines aléatoires et faire des statistiques basiques)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Post traitement\n",
    " A kindof aposteriori on the data using the apriori of : if one locutor speaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
