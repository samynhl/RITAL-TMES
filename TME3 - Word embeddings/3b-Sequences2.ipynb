{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8279abe5",
   "metadata": {},
   "source": [
    "# Word Embedding for Sequence Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4879c909",
   "metadata": {},
   "source": [
    "**The goal of this practical is to use pre-trained word embedding for adressing the sequence prediction tasks studied in week 2: PoS and chunking.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdc2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527dba92",
   "metadata": {},
   "source": [
    "## 0) Loading PoS (or chunking) datasets (small or large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1478369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    listeDoc = list()\n",
    "    with open(filename, \"r\") as f:\n",
    "        doc = list()\n",
    "        for ligne in f:\n",
    "            #print \"l : \",len(ligne),\" \",ligne\n",
    "            if len(ligne) < 2: # fin de doc\n",
    "                listeDoc.append(doc)\n",
    "                doc = list()\n",
    "                continue\n",
    "            mots = ligne.replace(\"\\n\",\"\").split(\" \")\n",
    "            # mettre mots[2] Ã  la place de mots[1] pour le chuncking\n",
    "            doc.append((mots[0],mots[1]))\n",
    "    return listeDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0514890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823  docs read\n",
      "77  docs (T) read\n"
     ]
    }
   ],
   "source": [
    "bSmall = True\n",
    "\n",
    "if(bSmall==True):\n",
    "    filename = \"ressources/conll2000/chtrain.txt\" \n",
    "    filenameT = \"ressources/conll2000/chtest.txt\" \n",
    "\n",
    "else:\n",
    "    # Larger corpus .\n",
    "    filename = \"ressources/conll2000/train.txt\" \n",
    "    filenameT = \"ressources/conll2000/test.txt\" \n",
    "\n",
    "alldocs = load(filename)\n",
    "alldocsT = load(filenameT)\n",
    "\n",
    "print(len(alldocs),\" docs read\")\n",
    "print(len(alldocsT),\" docs (T) read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a10ae1",
   "metadata": {},
   "source": [
    "# 1) Word embedding for classifying each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91fa49d",
   "metadata": {},
   "source": [
    "### Pre-trained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9688afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "bload = True\n",
    "fname = \"word2vec-google-news-300\"\n",
    "sdir = \"ressources/\" # Change\n",
    "\n",
    "if(bload==True):\n",
    "    wv_pre_trained = KeyedVectors.load(sdir+fname+\".dat\")\n",
    "else:    \n",
    "    wv_pre_trained = api.load(fname)\n",
    "    wv_pre_trained.save(sdir+fname+\".dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9dc19",
   "metadata": {},
   "source": [
    "### Some token on the dataset are missing, we will encode them with a random vector\n",
    "This is sub-optimal, but we need to do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b38abc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomvec():\n",
    "    default = np.random.randn(300)\n",
    "    default = default  / np.linalg.norm(default)\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfd9a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** Document ****** 1\n",
      "'s  not in WE, adding it with random vector\n",
      "a  not in WE, adding it with random vector\n",
      "to  not in WE, adding it with random vector\n",
      "747  not in WE, adding it with random vector\n",
      ".  not in WE, adding it with random vector\n",
      " ****** Document ****** 2\n",
      "200  not in WE, adding it with random vector\n",
      "so-called  not in WE, adding it with random vector\n",
      " ****** Document ****** 3\n",
      ",  not in WE, adding it with random vector\n",
      "and  not in WE, adding it with random vector\n",
      " ****** Document ****** 4\n",
      "793  not in WE, adding it with random vector\n",
      "of  not in WE, adding it with random vector\n",
      " ****** Document ****** 5\n",
      " ****** Document ****** 6\n",
      " ****** Document ****** 7\n",
      "59  not in WE, adding it with random vector\n",
      " ****** Document ****** 8\n",
      " ****** Document ****** 9\n",
      "SHEARSON  not in WE, adding it with random vector\n",
      " ****** Document ****** 10\n",
      "42  not in WE, adding it with random vector\n",
      "Balcor  not in WE, adding it with random vector\n",
      " ****** Document ****** 11\n",
      " ****** Document ****** 12\n",
      " ****** Document ****** 13\n",
      "real-estate  not in WE, adding it with random vector\n",
      "asset-management  not in WE, adding it with random vector\n",
      " ****** Document ****** 14\n",
      "44  not in WE, adding it with random vector\n",
      " ****** Document ****** 15\n",
      "60%-held  not in WE, adding it with random vector\n",
      " ****** Document ****** 16\n",
      "third-quarter  not in WE, adding it with random vector\n",
      "59.4  not in WE, adding it with random vector\n",
      "2.48  not in WE, adding it with random vector\n",
      " ****** Document ****** 17\n",
      "8.1  not in WE, adding it with random vector\n",
      "33  not in WE, adding it with random vector\n",
      " ****** Document ****** 18\n",
      "58.3  not in WE, adding it with random vector\n",
      "2.44  not in WE, adding it with random vector\n",
      "29.5  not in WE, adding it with random vector\n",
      "1.20  not in WE, adding it with random vector\n",
      "1988  not in WE, adding it with random vector\n",
      " ****** Document ****** 19\n",
      "loan-loss  not in WE, adding it with random vector\n",
      "93  not in WE, adding it with random vector\n",
      "217  not in WE, adding it with random vector\n",
      " ****** Document ****** 20\n",
      "10  not in WE, adding it with random vector\n",
      " ****** Document ****** 21\n",
      " ****** Document ****** 22\n",
      "7.6  not in WE, adding it with random vector\n",
      " ****** Document ****** 23\n",
      "Arbitragers  not in WE, adding it with random vector\n",
      " ****** Document ****** 24\n",
      " ****** Document ****** 25\n",
      "24.875  not in WE, adding it with random vector\n",
      "198  not in WE, adding it with random vector\n",
      " ****** Document ****** 26\n",
      "49.5  not in WE, adding it with random vector\n",
      "management-led  not in WE, adding it with random vector\n",
      "buy-out  not in WE, adding it with random vector\n",
      "300  not in WE, adding it with random vector\n",
      " ****** Document ****** 27\n",
      " ****** Document ****** 28\n",
      "250  not in WE, adding it with random vector\n",
      "25  not in WE, adding it with random vector\n",
      " ****** Document ****** 29\n",
      "75,000  not in WE, adding it with random vector\n",
      "250,000  not in WE, adding it with random vector\n",
      "83.3125  not in WE, adding it with random vector\n",
      " ****** Document ****** 30\n",
      "300-a-share  not in WE, adding it with random vector\n",
      "76.7  not in WE, adding it with random vector\n",
      " ****** Document ****** 31\n",
      "43.5  not in WE, adding it with random vector\n",
      " ****** Document ****** 32\n",
      "48  not in WE, adding it with random vector\n",
      " ****** Document ****** 33\n",
      "stock-option  not in WE, adding it with random vector\n",
      "22  not in WE, adding it with random vector\n",
      "15  not in WE, adding it with random vector\n",
      " ****** Document ****** 34\n",
      "575,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 35\n",
      "40-year  not in WE, adding it with random vector\n",
      "--  not in WE, adding it with random vector\n",
      " ****** Document ****** 36\n",
      "375,000  not in WE, adding it with random vector\n",
      "342,122  not in WE, adding it with random vector\n",
      "280,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 37\n",
      "10,000  not in WE, adding it with random vector\n",
      "150,000  not in WE, adding it with random vector\n",
      "69  not in WE, adding it with random vector\n",
      " ****** Document ****** 38\n",
      "37.7  not in WE, adding it with random vector\n",
      "21.3  not in WE, adding it with random vector\n",
      " ****** Document ****** 39\n",
      "114.4  not in WE, adding it with random vector\n",
      " ****** Document ****** 40\n",
      "first-class  not in WE, adding it with random vector\n",
      "20,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 41\n",
      "scaled-back  not in WE, adding it with random vector\n",
      " ****** Document ****** 42\n",
      "Coatedboard  not in WE, adding it with random vector\n",
      " ****** Document ****** 43\n",
      " ****** Document ****** 44\n",
      " ****** Document ****** 45\n",
      " ****** Document ****** 46\n",
      "``  not in WE, adding it with random vector\n",
      "''  not in WE, adding it with random vector\n",
      " ****** Document ****** 47\n",
      " ****** Document ****** 48\n",
      " ****** Document ****** 49\n",
      " ****** Document ****** 50\n",
      "Kadonada  not in WE, adding it with random vector\n",
      " ****** Document ****** 51\n",
      "112,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 52\n",
      " ****** Document ****** 53\n",
      "buy-back  not in WE, adding it with random vector\n",
      "3.7  not in WE, adding it with random vector\n",
      "30  not in WE, adding it with random vector\n",
      " ****** Document ****** 54\n",
      "over-the-counter  not in WE, adding it with random vector\n",
      "3.625  not in WE, adding it with random vector\n",
      " ****** Document ****** 55\n",
      "big-selling  not in WE, adding it with random vector\n",
      " ****** Document ****** 56\n",
      ";  not in WE, adding it with random vector\n",
      "Warner-Lambert  not in WE, adding it with random vector\n",
      "24  not in WE, adding it with random vector\n",
      " ****** Document ****** 57\n",
      "'  not in WE, adding it with random vector\n",
      " ****** Document ****** 58\n",
      " ****** Document ****** 59\n",
      "health-products  not in WE, adding it with random vector\n",
      " ****** Document ****** 60\n",
      "first-nine-month  not in WE, adding it with random vector\n",
      " ****** Document ****** 61\n",
      "47  not in WE, adding it with random vector\n",
      "50  not in WE, adding it with random vector\n",
      " ****** Document ****** 62\n",
      "1.63  not in WE, adding it with random vector\n",
      "1.47  not in WE, adding it with random vector\n",
      " ****** Document ****** 63\n",
      "cholesterol-lowering  not in WE, adding it with random vector\n",
      " ****** Document ****** 64\n",
      " ****** Document ****** 65\n",
      "animal-health  not in WE, adding it with random vector\n",
      "Aldomet  not in WE, adding it with random vector\n",
      " ****** Document ****** 66\n",
      "75.25  not in WE, adding it with random vector\n",
      " ****** Document ****** 67\n",
      " ****** Document ****** 68\n",
      "20  not in WE, adding it with random vector\n",
      "per-share  not in WE, adding it with random vector\n",
      " ****** Document ****** 69\n",
      "world-wide  not in WE, adding it with random vector\n",
      "1989  not in WE, adding it with random vector\n",
      "6.10  not in WE, adding it with random vector\n",
      " ****** Document ****** 70\n",
      "1.11  not in WE, adding it with random vector\n",
      "1.03  not in WE, adding it with random vector\n",
      " ****** Document ****** 71\n",
      "Prescription-drug  not in WE, adding it with random vector\n",
      "340  not in WE, adding it with random vector\n",
      " ****** Document ****** 72\n",
      "Dilzem  not in WE, adding it with random vector\n",
      " ****** Document ****** 73\n",
      "World-wide  not in WE, adding it with random vector\n",
      "non-prescription  not in WE, adding it with random vector\n",
      "health-care  not in WE, adding it with random vector\n",
      "362  not in WE, adding it with random vector\n",
      " ****** Document ****** 74\n",
      " ****** Document ****** 75\n",
      "12  not in WE, adding it with random vector\n",
      "277  not in WE, adding it with random vector\n",
      " ****** Document ****** 76\n",
      "109.50  not in WE, adding it with random vector\n",
      "1.50  not in WE, adding it with random vector\n",
      " ****** Document ****** 77\n",
      " ****** Document ****** 78\n",
      "nine-month  not in WE, adding it with random vector\n",
      "plant-science  not in WE, adding it with random vector\n",
      " ****** Document ****** 79\n",
      "1987  not in WE, adding it with random vector\n",
      " ****** Document ****** 80\n",
      "Third-quarter  not in WE, adding it with random vector\n",
      "11  not in WE, adding it with random vector\n",
      "1.045  not in WE, adding it with random vector\n",
      "940.6  not in WE, adding it with random vector\n",
      " ****** Document ****** 81\n",
      "Nine-month  not in WE, adding it with random vector\n",
      "3.39  not in WE, adding it with random vector\n",
      "3.03  not in WE, adding it with random vector\n",
      " ****** Document ****** 82\n",
      "anti-depressant  not in WE, adding it with random vector\n",
      "drug-sales  not in WE, adding it with random vector\n",
      " ****** Document ****** 83\n",
      " ****** Document ****** 84\n",
      "medical-instrument  not in WE, adding it with random vector\n",
      " ****** Document ****** 85\n",
      "62.25  not in WE, adding it with random vector\n",
      "12.5  not in WE, adding it with random vector\n",
      " ****** Document ****** 86\n",
      "Colgate-Palmolive  not in WE, adding it with random vector\n",
      "95  not in WE, adding it with random vector\n",
      "1.05  not in WE, adding it with random vector\n",
      " ****** Document ****** 87\n",
      "88  not in WE, adding it with random vector\n",
      " ****** Document ****** 88\n",
      "consumer-products  not in WE, adding it with random vector\n",
      "69.5  not in WE, adding it with random vector\n",
      "76  not in WE, adding it with random vector\n",
      "47.1  not in WE, adding it with random vector\n",
      "year-before  not in WE, adding it with random vector\n",
      " ****** Document ****** 89\n",
      "1.29  not in WE, adding it with random vector\n",
      " ****** Document ****** 90\n",
      " ****** Document ****** 91\n",
      " ****** Document ****** 92\n",
      "personal-care  not in WE, adding it with random vector\n",
      " ****** Document ****** 93\n",
      " ****** Document ****** 94\n",
      " ****** Document ****** 95\n",
      " ****** Document ****** 96\n",
      " ****** Document ****** 97\n",
      " ****** Document ****** 98\n",
      " ****** Document ****** 99\n",
      " ****** Document ****** 100\n",
      "-LCB-  not in WE, adding it with random vector\n",
      "-RCB-  not in WE, adding it with random vector\n",
      " ****** Document ****** 101\n",
      " ****** Document ****** 102\n",
      " ****** Document ****** 103\n",
      "Ittleson  not in WE, adding it with random vector\n",
      " ****** Document ****** 104\n",
      "cable-television  not in WE, adding it with random vector\n",
      " ****** Document ****** 105\n",
      " ****** Document ****** 106\n",
      " ****** Document ****** 107\n",
      " ****** Document ****** 108\n",
      " ****** Document ****** 109\n",
      " ****** Document ****** 110\n",
      " ****** Document ****** 111\n",
      " ****** Document ****** 112\n",
      " ****** Document ****** 113\n",
      " ****** Document ****** 114\n",
      "...  not in WE, adding it with random vector\n",
      "19  not in WE, adding it with random vector\n",
      " ****** Document ****** 115\n",
      "-LRB-  not in WE, adding it with random vector\n",
      "-RRB-  not in WE, adding it with random vector\n",
      " ****** Document ****** 116\n",
      " ****** Document ****** 117\n",
      " ****** Document ****** 118\n",
      " ****** Document ****** 119\n",
      " ****** Document ****** 120\n",
      "Good-bye  not in WE, adding it with random vector\n",
      "27  not in WE, adding it with random vector\n",
      " ****** Document ****** 121\n",
      "?  not in WE, adding it with random vector\n",
      " ****** Document ****** 122\n",
      " ****** Document ****** 123\n",
      " ****** Document ****** 124\n",
      " ****** Document ****** 125\n",
      " ****** Document ****** 126\n",
      "hunter-gatherers  not in WE, adding it with random vector\n",
      " ****** Document ****** 127\n",
      " ****** Document ****** 128\n",
      "present-day  not in WE, adding it with random vector\n",
      " ****** Document ****** 129\n",
      "capitalist-exploiters-greedy-American-consumers-global  not in WE, adding it with random vector\n",
      "-  not in WE, adding it with random vector\n",
      " ****** Document ****** 130\n",
      " ****** Document ****** 131\n",
      " ****** Document ****** 132\n",
      "tax-collecting  not in WE, adding it with random vector\n",
      "high-level  not in WE, adding it with random vector\n",
      "120,000-employee  not in WE, adding it with random vector\n",
      ":  not in WE, adding it with random vector\n",
      " ****** Document ****** 133\n",
      " ****** Document ****** 134\n",
      " ****** Document ****** 135\n",
      " ****** Document ****** 136\n",
      " ****** Document ****** 137\n",
      " ****** Document ****** 138\n",
      "1961  not in WE, adding it with random vector\n",
      " ****** Document ****** 139\n",
      "360  not in WE, adding it with random vector\n",
      " ****** Document ****** 140\n",
      " ****** Document ****** 141\n",
      " ****** Document ****** 142\n",
      " ****** Document ****** 143\n",
      " ****** Document ****** 144\n",
      "70,000  not in WE, adding it with random vector\n",
      "80,000  not in WE, adding it with random vector\n",
      "top-notch  not in WE, adding it with random vector\n",
      " ****** Document ****** 145\n",
      " ****** Document ****** 146\n",
      " ****** Document ****** 147\n",
      "Giroldi  not in WE, adding it with random vector\n",
      " ****** Document ****** 148\n",
      " ****** Document ****** 149\n",
      "Battalion-2000  not in WE, adding it with random vector\n",
      " ****** Document ****** 150\n",
      "70  not in WE, adding it with random vector\n",
      " ****** Document ****** 151\n",
      " ****** Document ****** 152\n",
      "full-time  not in WE, adding it with random vector\n",
      " ****** Document ****** 153\n",
      "coup-makers  not in WE, adding it with random vector\n",
      " ****** Document ****** 154\n",
      " ****** Document ****** 155\n",
      " ****** Document ****** 156\n",
      " ****** Document ****** 157\n",
      " ****** Document ****** 158\n",
      " ****** Document ****** 159\n",
      " ****** Document ****** 160\n",
      "1960  not in WE, adding it with random vector\n",
      "spy-in-training  not in WE, adding it with random vector\n",
      " ****** Document ****** 161\n",
      " ****** Document ****** 162\n",
      " ****** Document ****** 163\n",
      " ****** Document ****** 164\n",
      " ****** Document ****** 165\n",
      " ****** Document ****** 166\n",
      "55-year-old  not in WE, adding it with random vector\n",
      "well-born  not in WE, adding it with random vector\n",
      " ****** Document ****** 167\n",
      " ****** Document ****** 168\n",
      " ****** Document ****** 169\n",
      " ****** Document ****** 170\n",
      " ****** Document ****** 171\n",
      " ****** Document ****** 172\n",
      " ****** Document ****** 173\n",
      " ****** Document ****** 174\n",
      " ****** Document ****** 175\n",
      "hand-sized  not in WE, adding it with random vector\n",
      " ****** Document ****** 176\n",
      " ****** Document ****** 177\n",
      " ****** Document ****** 178\n",
      " ****** Document ****** 179\n",
      " ****** Document ****** 180\n",
      " ****** Document ****** 181\n",
      "1959  not in WE, adding it with random vector\n",
      " ****** Document ****** 182\n",
      "half-brother  not in WE, adding it with random vector\n",
      " ****** Document ****** 183\n",
      " ****** Document ****** 184\n",
      " ****** Document ****** 185\n",
      " ****** Document ****** 186\n",
      " ****** Document ****** 187\n",
      " ****** Document ****** 188\n",
      "well-off  not in WE, adding it with random vector\n",
      "French-modeled  not in WE, adding it with random vector\n",
      " ****** Document ****** 189\n",
      "French-made  not in WE, adding it with random vector\n",
      " ****** Document ****** 190\n",
      " ****** Document ****** 191\n",
      "1966  not in WE, adding it with random vector\n",
      "1967  not in WE, adding it with random vector\n",
      " ****** Document ****** 192\n",
      " ****** Document ****** 193\n",
      " ****** Document ****** 194\n",
      " ****** Document ****** 195\n",
      " ****** Document ****** 196\n",
      "100  not in WE, adding it with random vector\n",
      " ****** Document ****** 197\n",
      "400  not in WE, adding it with random vector\n",
      " ****** Document ****** 198\n",
      " ****** Document ****** 199\n",
      " ****** Document ****** 200\n",
      "1964  not in WE, adding it with random vector\n",
      "tailor-made  not in WE, adding it with random vector\n",
      "super-spy  not in WE, adding it with random vector\n",
      " ****** Document ****** 201\n",
      " ****** Document ****** 202\n",
      " ****** Document ****** 203\n",
      " ****** Document ****** 204\n",
      " ****** Document ****** 205\n",
      "banana-exporting  not in WE, adding it with random vector\n",
      " ****** Document ****** 206\n",
      " ****** Document ****** 207\n",
      " ****** Document ****** 208\n",
      " ****** Document ****** 209\n",
      " ****** Document ****** 210\n",
      " ****** Document ****** 211\n",
      " ****** Document ****** 212\n",
      "human-rights  not in WE, adding it with random vector\n",
      " ****** Document ****** 213\n",
      " ****** Document ****** 214\n",
      " ****** Document ****** 215\n",
      " ****** Document ****** 216\n",
      "counter-intelligence  not in WE, adding it with random vector\n",
      "1983  not in WE, adding it with random vector\n",
      " ****** Document ****** 217\n",
      "two-month  not in WE, adding it with random vector\n",
      " ****** Document ****** 218\n",
      " ****** Document ****** 219\n",
      "G-2  not in WE, adding it with random vector\n",
      "1970  not in WE, adding it with random vector\n",
      " ****** Document ****** 220\n",
      " ****** Document ****** 221\n",
      " ****** Document ****** 222\n",
      " ****** Document ****** 223\n",
      "rent-a-colonel  not in WE, adding it with random vector\n",
      "inter-American  not in WE, adding it with random vector\n",
      "1977  not in WE, adding it with random vector\n",
      " ****** Document ****** 224\n",
      " ****** Document ****** 225\n",
      " ****** Document ****** 226\n",
      " ****** Document ****** 227\n",
      " ****** Document ****** 228\n",
      " ****** Document ****** 229\n",
      " ****** Document ****** 230\n",
      " ****** Document ****** 231\n",
      " ****** Document ****** 232\n",
      "1976  not in WE, adding it with random vector\n",
      "470th  not in WE, adding it with random vector\n",
      " ****** Document ****** 233\n",
      " ****** Document ****** 234\n",
      " ****** Document ****** 235\n",
      " ****** Document ****** 236\n",
      " ****** Document ****** 237\n",
      " ****** Document ****** 238\n",
      " ****** Document ****** 239\n",
      " ****** Document ****** 240\n",
      "gun-running  not in WE, adding it with random vector\n",
      " ****** Document ****** 241\n",
      " ****** Document ****** 242\n",
      "Wittgreen  not in WE, adding it with random vector\n",
      " ****** Document ****** 243\n",
      " ****** Document ****** 244\n",
      "1979  not in WE, adding it with random vector\n",
      " ****** Document ****** 245\n",
      " ****** Document ****** 246\n",
      " ****** Document ****** 247\n",
      " ****** Document ****** 248\n",
      " ****** Document ****** 249\n",
      " ****** Document ****** 250\n",
      " ****** Document ****** 251\n",
      " ****** Document ****** 252\n",
      " ****** Document ****** 253\n",
      " ****** Document ****** 254\n",
      "reindicting  not in WE, adding it with random vector\n",
      " ****** Document ****** 255\n",
      "1980  not in WE, adding it with random vector\n",
      " ****** Document ****** 256\n",
      " ****** Document ****** 257\n",
      " ****** Document ****** 258\n",
      " ****** Document ****** 259\n",
      " ****** Document ****** 260\n",
      " ****** Document ****** 261\n",
      " ****** Document ****** 262\n",
      " ****** Document ****** 263\n",
      " ****** Document ****** 264\n",
      "de-facto  not in WE, adding it with random vector\n",
      " ****** Document ****** 265\n",
      " ****** Document ****** 266\n",
      " ****** Document ****** 267\n",
      "200,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 268\n",
      " ****** Document ****** 269\n",
      " ****** Document ****** 270\n",
      " ****** Document ****** 271\n",
      " ****** Document ****** 272\n",
      " ****** Document ****** 273\n",
      " ****** Document ****** 274\n",
      "1985  not in WE, adding it with random vector\n",
      " ****** Document ****** 275\n",
      " ****** Document ****** 276\n",
      " ****** Document ****** 277\n",
      "1984  not in WE, adding it with random vector\n",
      " ****** Document ****** 278\n",
      " ****** Document ****** 279\n",
      " ****** Document ****** 280\n",
      " ****** Document ****** 281\n",
      " ****** Document ****** 282\n",
      " ****** Document ****** 283\n",
      " ****** Document ****** 284\n",
      " ****** Document ****** 285\n",
      "100,000  not in WE, adding it with random vector\n",
      "D.C  not in WE, adding it with random vector\n",
      " ****** Document ****** 286\n",
      " ****** Document ****** 287\n",
      " ****** Document ****** 288\n",
      " ****** Document ****** 289\n",
      " ****** Document ****** 290\n",
      " ****** Document ****** 291\n",
      "1986  not in WE, adding it with random vector\n",
      " ****** Document ****** 292\n",
      " ****** Document ****** 293\n",
      " ****** Document ****** 294\n",
      " ****** Document ****** 295\n",
      " ****** Document ****** 296\n",
      " ****** Document ****** 297\n",
      " ****** Document ****** 298\n",
      " ****** Document ****** 299\n",
      "Iran-Contra  not in WE, adding it with random vector\n",
      " ****** Document ****** 300\n",
      "anti-Noriega  not in WE, adding it with random vector\n",
      " ****** Document ****** 301\n",
      " ****** Document ****** 302\n",
      " ****** Document ****** 303\n",
      " ****** Document ****** 304\n",
      " ****** Document ****** 305\n",
      " ****** Document ****** 306\n",
      " ****** Document ****** 307\n",
      " ****** Document ****** 308\n",
      "knock-out  not in WE, adding it with random vector\n",
      " ****** Document ****** 309\n",
      "well-intentioned  not in WE, adding it with random vector\n",
      " ****** Document ****** 310\n",
      " ****** Document ****** 311\n",
      "short-term  not in WE, adding it with random vector\n",
      " ****** Document ****** 312\n",
      " ****** Document ****** 313\n",
      " ****** Document ****** 314\n",
      "UPJOHN  not in WE, adding it with random vector\n",
      "96  not in WE, adding it with random vector\n",
      "52  not in WE, adding it with random vector\n",
      "89.6  not in WE, adding it with random vector\n",
      "49  not in WE, adding it with random vector\n",
      " ****** Document ****** 315\n",
      " ****** Document ****** 316\n",
      "0.1  not in WE, adding it with random vector\n",
      " ****** Document ****** 317\n",
      "1.3  not in WE, adding it with random vector\n",
      "3.3  not in WE, adding it with random vector\n",
      " ****** Document ****** 318\n",
      " ****** Document ****** 319\n",
      "105,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 320\n",
      " ****** Document ****** 321\n",
      "83.6  not in WE, adding it with random vector\n",
      "83.8  not in WE, adding it with random vector\n",
      " ****** Document ****** 322\n",
      " ****** Document ****** 323\n",
      "0.2  not in WE, adding it with random vector\n",
      " ****** Document ****** 324\n",
      "83.7  not in WE, adding it with random vector\n",
      "84.1  not in WE, adding it with random vector\n",
      " ****** Document ****** 325\n",
      " ****** Document ****** 326\n",
      " ****** Document ****** 327\n",
      " ****** Document ****** 328\n",
      "0.3  not in WE, adding it with random vector\n",
      " ****** Document ****** 329\n",
      " ****** Document ****** 330\n",
      " ****** Document ****** 331\n",
      " ****** Document ****** 332\n",
      " ****** Document ****** 333\n",
      " ****** Document ****** 334\n",
      " ****** Document ****** 335\n",
      " ****** Document ****** 336\n",
      "142.3  not in WE, adding it with random vector\n",
      " ****** Document ****** 337\n",
      " ****** Document ****** 338\n",
      "NESB  not in WE, adding it with random vector\n",
      " ****** Document ****** 339\n",
      "Omnibank  not in WE, adding it with random vector\n",
      " ****** Document ****** 340\n",
      "Lung-cancer  not in WE, adding it with random vector\n",
      "45  not in WE, adding it with random vector\n",
      " ****** Document ****** 341\n",
      " ****** Document ****** 342\n",
      " ****** Document ****** 343\n",
      " ****** Document ****** 344\n",
      "Tockman  not in WE, adding it with random vector\n",
      " ****** Document ****** 345\n",
      "35  not in WE, adding it with random vector\n",
      " ****** Document ****** 346\n",
      "mid-1970s  not in WE, adding it with random vector\n",
      "13.4  not in WE, adding it with random vector\n",
      "mid-1980s  not in WE, adding it with random vector\n",
      "9.6  not in WE, adding it with random vector\n",
      "28.7  not in WE, adding it with random vector\n",
      " ****** Document ****** 347\n",
      "14.2  not in WE, adding it with random vector\n",
      " ****** Document ****** 348\n",
      "8.9  not in WE, adding it with random vector\n",
      "5.3  not in WE, adding it with random vector\n",
      " ****** Document ****** 349\n",
      "35-44  not in WE, adding it with random vector\n",
      " ****** Document ****** 350\n",
      "lung-cancer  not in WE, adding it with random vector\n",
      "1990s  not in WE, adding it with random vector\n",
      "2000  not in WE, adding it with random vector\n",
      " ****** Document ****** 351\n",
      "55  not in WE, adding it with random vector\n",
      " ****** Document ****** 352\n",
      " ****** Document ****** 353\n",
      " ****** Document ****** 354\n",
      " ****** Document ****** 355\n",
      " ****** Document ****** 356\n",
      " ****** Document ****** 357\n",
      "Stjernsward  not in WE, adding it with random vector\n",
      " ****** Document ****** 358\n",
      "Non-smoking  not in WE, adding it with random vector\n",
      "anti-smoking  not in WE, adding it with random vector\n",
      " ****** Document ****** 359\n",
      " ****** Document ****** 360\n",
      "85  not in WE, adding it with random vector\n",
      "75  not in WE, adding it with random vector\n",
      " ****** Document ****** 361\n",
      " ****** Document ****** 362\n",
      " ****** Document ****** 363\n",
      " ****** Document ****** 364\n",
      " ****** Document ****** 365\n",
      " ****** Document ****** 366\n",
      "age-specific  not in WE, adding it with random vector\n",
      " ****** Document ****** 367\n",
      " ****** Document ****** 368\n",
      " ****** Document ****** 369\n",
      " ****** Document ****** 370\n",
      " ****** Document ****** 371\n",
      "president\\/product  not in WE, adding it with random vector\n",
      " ****** Document ****** 372\n",
      "president\\/national-government  not in WE, adding it with random vector\n",
      "P&G  not in WE, adding it with random vector\n",
      "government-relations  not in WE, adding it with random vector\n",
      " ****** Document ****** 373\n",
      " ****** Document ****** 374\n",
      "53  not in WE, adding it with random vector\n",
      " ****** Document ****** 375\n",
      " ****** Document ****** 376\n",
      "run-up  not in WE, adding it with random vector\n",
      " ****** Document ****** 377\n",
      "computer-guided  not in WE, adding it with random vector\n",
      "profit-driven  not in WE, adding it with random vector\n",
      " ****** Document ****** 378\n",
      " ****** Document ****** 379\n",
      "459.93  not in WE, adding it with random vector\n",
      " ****** Document ****** 380\n",
      " ****** Document ****** 381\n",
      "449.89  not in WE, adding it with random vector\n",
      "0.4  not in WE, adding it with random vector\n",
      " ****** Document ****** 382\n",
      "448.49  not in WE, adding it with random vector\n",
      "1.40  not in WE, adding it with random vector\n",
      " ****** Document ****** 383\n",
      "2.51  not in WE, adding it with random vector\n",
      "453.57  not in WE, adding it with random vector\n",
      " ****** Document ****** 384\n",
      " ****** Document ****** 385\n",
      " ****** Document ****** 386\n",
      " ****** Document ****** 387\n",
      " ****** Document ****** 388\n",
      " ****** Document ****** 389\n",
      " ****** Document ****** 390\n",
      " ****** Document ****** 391\n",
      " ****** Document ****** 392\n",
      " ****** Document ****** 393\n",
      " ****** Document ****** 394\n",
      " ****** Document ****** 395\n",
      " ****** Document ****** 396\n",
      " ****** Document ****** 397\n",
      "161.5  not in WE, adding it with random vector\n",
      " ****** Document ****** 398\n",
      " ****** Document ****** 399\n",
      "4,345  not in WE, adding it with random vector\n",
      "1,174  not in WE, adding it with random vector\n",
      "1,040  not in WE, adding it with random vector\n",
      " ****** Document ****** 400\n",
      " ****** Document ****** 401\n",
      "29  not in WE, adding it with random vector\n",
      "1\\/2  not in WE, adding it with random vector\n",
      "3\\/4  not in WE, adding it with random vector\n",
      "28  not in WE, adding it with random vector\n",
      "1\\/4  not in WE, adding it with random vector\n",
      " ****** Document ****** 402\n",
      " ****** Document ****** 403\n",
      "anti-anemia  not in WE, adding it with random vector\n",
      " ****** Document ****** 404\n",
      "26  not in WE, adding it with random vector\n",
      " ****** Document ****** 405\n",
      "13.6  not in WE, adding it with random vector\n",
      " ****** Document ****** 406\n",
      "31  not in WE, adding it with random vector\n",
      " ****** Document ****** 407\n",
      "1.7  not in WE, adding it with random vector\n",
      " ****** Document ****** 408\n",
      " ****** Document ****** 409\n",
      "1990  not in WE, adding it with random vector\n",
      " ****** Document ****** 410\n",
      " ****** Document ****** 411\n",
      "stepped-up  not in WE, adding it with random vector\n",
      " ****** Document ****** 412\n",
      " ****** Document ****** 413\n",
      "character-recognition  not in WE, adding it with random vector\n",
      " ****** Document ****** 414\n",
      " ****** Document ****** 415\n",
      " ****** Document ****** 416\n",
      "5\\/8  not in WE, adding it with random vector\n",
      "3\\/8  not in WE, adding it with random vector\n",
      "4.7  not in WE, adding it with random vector\n",
      "63  not in WE, adding it with random vector\n",
      " ****** Document ****** 417\n",
      "43  not in WE, adding it with random vector\n",
      "1\\/8  not in WE, adding it with random vector\n",
      "1.27  not in WE, adding it with random vector\n",
      "1.15  not in WE, adding it with random vector\n",
      " ****** Document ****** 418\n",
      "177.3  not in WE, adding it with random vector\n",
      "154  not in WE, adding it with random vector\n",
      " ****** Document ****** 419\n",
      "A&W  not in WE, adding it with random vector\n",
      " ****** Document ****** 420\n",
      "18  not in WE, adding it with random vector\n",
      " ****** Document ****** 421\n",
      " ****** Document ****** 422\n",
      " ****** Document ****** 423\n",
      "39  not in WE, adding it with random vector\n",
      " ****** Document ****** 424\n",
      " ****** Document ****** 425\n",
      " ****** Document ****** 426\n",
      " ****** Document ****** 427\n",
      " ****** Document ****** 428\n",
      " ****** Document ****** 429\n",
      " ****** Document ****** 430\n",
      " ****** Document ****** 431\n",
      " ****** Document ****** 432\n",
      " ****** Document ****** 433\n",
      "sanitationists  not in WE, adding it with random vector\n",
      " ****** Document ****** 434\n",
      " ****** Document ****** 435\n",
      "cast-iron  not in WE, adding it with random vector\n",
      "water-treatment  not in WE, adding it with random vector\n",
      "19th  not in WE, adding it with random vector\n",
      " ****** Document ****** 436\n",
      " ****** Document ****** 437\n",
      "20th  not in WE, adding it with random vector\n",
      "private-sector  not in WE, adding it with random vector\n",
      " ****** Document ****** 438\n",
      "well-being  not in WE, adding it with random vector\n",
      " ****** Document ****** 439\n",
      "public-health  not in WE, adding it with random vector\n",
      " ****** Document ****** 440\n",
      "1962  not in WE, adding it with random vector\n",
      " ****** Document ****** 441\n",
      " ****** Document ****** 442\n",
      " ****** Document ****** 443\n",
      "1960s  not in WE, adding it with random vector\n",
      " ****** Document ****** 444\n",
      " ****** Document ****** 445\n",
      " ****** Document ****** 446\n",
      " ****** Document ****** 447\n",
      " ****** Document ****** 448\n",
      " ****** Document ****** 449\n",
      " ****** Document ****** 450\n",
      " ****** Document ****** 451\n",
      " ****** Document ****** 452\n",
      " ****** Document ****** 453\n",
      " ****** Document ****** 454\n",
      " ****** Document ****** 455\n",
      " ****** Document ****** 456\n",
      " ****** Document ****** 457\n",
      "blue-ribbon  not in WE, adding it with random vector\n",
      " ****** Document ****** 458\n",
      " ****** Document ****** 459\n",
      " ****** Document ****** 460\n",
      " ****** Document ****** 461\n",
      " ****** Document ****** 462\n",
      " ****** Document ****** 463\n",
      "non-objective  not in WE, adding it with random vector\n",
      " ****** Document ****** 464\n",
      "business-as-usual  not in WE, adding it with random vector\n",
      " ****** Document ****** 465\n",
      " ****** Document ****** 466\n",
      " ****** Document ****** 467\n",
      " ****** Document ****** 468\n",
      " ****** Document ****** 469\n",
      " ****** Document ****** 470\n",
      " ****** Document ****** 471\n",
      "Coca-Cola  not in WE, adding it with random vector\n",
      "68  not in WE, adding it with random vector\n",
      " ****** Document ****** 472\n",
      "12.7  not in WE, adding it with random vector\n",
      "39.9  not in WE, adding it with random vector\n",
      " ****** Document ****** 473\n",
      "37  not in WE, adding it with random vector\n",
      " ****** Document ****** 474\n",
      " ****** Document ****** 475\n",
      "1.02  not in WE, adding it with random vector\n",
      " ****** Document ****** 476\n",
      "year-ago  not in WE, adding it with random vector\n",
      " ****** Document ****** 477\n",
      " ****** Document ****** 478\n",
      "soft-drink  not in WE, adding it with random vector\n",
      " ****** Document ****** 479\n",
      " ****** Document ****** 480\n",
      " ****** Document ****** 481\n",
      "soft-drinks  not in WE, adding it with random vector\n",
      " ****** Document ****** 482\n",
      " ****** Document ****** 483\n",
      "higher-priced  not in WE, adding it with random vector\n",
      " ****** Document ****** 484\n",
      "14  not in WE, adding it with random vector\n",
      "324.9  not in WE, adding it with random vector\n",
      " ****** Document ****** 485\n",
      " ****** Document ****** 486\n",
      "65  not in WE, adding it with random vector\n",
      "93.8  not in WE, adding it with random vector\n",
      " ****** Document ****** 487\n",
      "2.97  not in WE, adding it with random vector\n",
      " ****** Document ****** 488\n",
      "49%-owned  not in WE, adding it with random vector\n",
      "1.2  not in WE, adding it with random vector\n",
      " ****** Document ****** 489\n",
      "25-million-share  not in WE, adding it with random vector\n",
      "9.7  not in WE, adding it with random vector\n",
      " ****** Document ****** 490\n",
      "N.Y.-based  not in WE, adding it with random vector\n",
      "269.3  not in WE, adding it with random vector\n",
      "241.6  not in WE, adding it with random vector\n",
      "91  not in WE, adding it with random vector\n",
      " ****** Document ****** 491\n",
      "3.90  not in WE, adding it with random vector\n",
      "3.13  not in WE, adding it with random vector\n",
      " ****** Document ****** 492\n",
      "after-tax  not in WE, adding it with random vector\n",
      "5.9  not in WE, adding it with random vector\n",
      " ****** Document ****** 493\n",
      "16.375  not in WE, adding it with random vector\n",
      "62.5  not in WE, adding it with random vector\n",
      " ****** Document ****** 494\n",
      "58.50  not in WE, adding it with random vector\n",
      "1.375  not in WE, adding it with random vector\n",
      " ****** Document ****** 495\n",
      "L.J.  not in WE, adding it with random vector\n",
      " ****** Document ****** 496\n",
      " ****** Document ****** 497\n",
      "court-appointed  not in WE, adding it with random vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ****** Document ****** 498\n",
      "financial-services  not in WE, adding it with random vector\n",
      " ****** Document ****** 499\n",
      " ****** Document ****** 500\n",
      " ****** Document ****** 501\n",
      "department-store  not in WE, adding it with random vector\n",
      " ****** Document ****** 502\n",
      "Sigoloff  not in WE, adding it with random vector\n",
      " ****** Document ****** 503\n",
      "80  not in WE, adding it with random vector\n",
      " ****** Document ****** 504\n",
      " ****** Document ****** 505\n",
      "77  not in WE, adding it with random vector\n",
      " ****** Document ****** 506\n",
      " ****** Document ****** 507\n",
      " ****** Document ****** 508\n",
      "62  not in WE, adding it with random vector\n",
      "2.5  not in WE, adding it with random vector\n",
      " ****** Document ****** 509\n",
      " ****** Document ****** 510\n",
      " ****** Document ****** 511\n",
      " ****** Document ****** 512\n",
      " ****** Document ****** 513\n",
      "1929  not in WE, adding it with random vector\n",
      " ****** Document ****** 514\n",
      " ****** Document ****** 515\n",
      " ****** Document ****** 516\n",
      "409  not in WE, adding it with random vector\n",
      " ****** Document ****** 517\n",
      " ****** Document ****** 518\n",
      "Universal-Rundle  not in WE, adding it with random vector\n",
      " ****** Document ****** 519\n",
      " ****** Document ****** 520\n",
      "vitreous-china  not in WE, adding it with random vector\n",
      " ****** Document ****** 521\n",
      " ****** Document ****** 522\n",
      "prime-time  not in WE, adding it with random vector\n",
      "also-ran  not in WE, adding it with random vector\n",
      " ****** Document ****** 523\n",
      " ****** Document ****** 524\n",
      " ****** Document ****** 525\n",
      "mid-season  not in WE, adding it with random vector\n",
      " ****** Document ****** 526\n",
      " ****** Document ****** 527\n",
      "news-oriented  not in WE, adding it with random vector\n",
      " ****** Document ****** 528\n",
      "line-up  not in WE, adding it with random vector\n",
      " ****** Document ****** 529\n",
      "one-hour  not in WE, adding it with random vector\n",
      " ****** Document ****** 530\n",
      "Kueneke  not in WE, adding it with random vector\n",
      " ****** Document ****** 531\n",
      " ****** Document ****** 532\n",
      " ****** Document ****** 533\n",
      " ****** Document ****** 534\n",
      "Cities\\/ABC  not in WE, adding it with random vector\n",
      " ****** Document ****** 535\n",
      " ****** Document ****** 536\n",
      " ****** Document ****** 537\n",
      " ****** Document ****** 538\n",
      " ****** Document ****** 539\n",
      "half-hour  not in WE, adding it with random vector\n",
      "family-oriented  not in WE, adding it with random vector\n",
      " ****** Document ****** 540\n",
      " ****** Document ****** 541\n",
      "300,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 542\n",
      "32.6  not in WE, adding it with random vector\n",
      " ****** Document ****** 543\n",
      "year-earlier  not in WE, adding it with random vector\n",
      "49.8  not in WE, adding it with random vector\n",
      " ****** Document ****** 544\n",
      "623  not in WE, adding it with random vector\n",
      "0.5  not in WE, adding it with random vector\n",
      "619.8  not in WE, adding it with random vector\n",
      " ****** Document ****** 545\n",
      "start-up  not in WE, adding it with random vector\n",
      " ****** Document ****** 546\n",
      " ****** Document ****** 547\n",
      "previous-year  not in WE, adding it with random vector\n",
      " ****** Document ****** 548\n",
      " ****** Document ****** 549\n",
      "155  not in WE, adding it with random vector\n",
      "2.33  not in WE, adding it with random vector\n",
      "17  not in WE, adding it with random vector\n",
      "187.8  not in WE, adding it with random vector\n",
      "2.82  not in WE, adding it with random vector\n",
      " ****** Document ****** 550\n",
      "5.2  not in WE, adding it with random vector\n",
      "2.04  not in WE, adding it with random vector\n",
      "1.94  not in WE, adding it with random vector\n",
      " ****** Document ****** 551\n",
      "1.75  not in WE, adding it with random vector\n",
      " ****** Document ****** 552\n",
      " ****** Document ****** 553\n",
      " ****** Document ****** 554\n",
      " ****** Document ****** 555\n",
      " ****** Document ****** 556\n",
      "38  not in WE, adding it with random vector\n",
      " ****** Document ****** 557\n",
      " ****** Document ****** 558\n",
      " ****** Document ****** 559\n",
      "high-risk  not in WE, adding it with random vector\n",
      " ****** Document ****** 560\n",
      " ****** Document ****** 561\n",
      "5-fluorouracil  not in WE, adding it with random vector\n",
      "colon-cancer  not in WE, adding it with random vector\n",
      " ****** Document ****** 562\n",
      "one-third  not in WE, adding it with random vector\n",
      "two-thirds  not in WE, adding it with random vector\n",
      " ****** Document ****** 563\n",
      " ****** Document ****** 564\n",
      " ****** Document ****** 565\n",
      " ****** Document ****** 566\n",
      " ****** Document ****** 567\n",
      " ****** Document ****** 568\n",
      " ****** Document ****** 569\n",
      " ****** Document ****** 570\n",
      "Moertel  not in WE, adding it with random vector\n",
      "M.D  not in WE, adding it with random vector\n",
      " ****** Document ****** 571\n",
      "cleaner-burning  not in WE, adding it with random vector\n",
      " ****** Document ****** 572\n",
      "cost-effective  not in WE, adding it with random vector\n",
      "air-pollution  not in WE, adding it with random vector\n",
      " ****** Document ****** 573\n",
      "front-running  not in WE, adding it with random vector\n",
      " ****** Document ****** 574\n",
      " ****** Document ****** 575\n",
      "public-relations  not in WE, adding it with random vector\n",
      "1997  not in WE, adding it with random vector\n",
      " ****** Document ****** 576\n",
      "lower-emission  not in WE, adding it with random vector\n",
      " ****** Document ****** 577\n",
      " ****** Document ****** 578\n",
      "21  not in WE, adding it with random vector\n",
      " ****** Document ****** 579\n",
      "1992  not in WE, adding it with random vector\n",
      "1993  not in WE, adding it with random vector\n",
      " ****** Document ****** 580\n",
      " ****** Document ****** 581\n",
      " ****** Document ****** 582\n",
      " ****** Document ****** 583\n",
      " ****** Document ****** 584\n",
      "alternative-fueled  not in WE, adding it with random vector\n",
      "1995  not in WE, adding it with random vector\n",
      " ****** Document ****** 585\n",
      "clean-fuels  not in WE, adding it with random vector\n",
      " ****** Document ****** 586\n",
      "clean-air  not in WE, adding it with random vector\n",
      " ****** Document ****** 587\n",
      " ****** Document ****** 588\n",
      "savings-and-loan  not in WE, adding it with random vector\n",
      " ****** Document ****** 589\n",
      "scandal-ridden  not in WE, adding it with random vector\n",
      " ****** Document ****** 590\n",
      " ****** Document ****** 591\n",
      " ****** Document ****** 592\n",
      "cease-and-desist  not in WE, adding it with random vector\n",
      " ****** Document ****** 593\n",
      " ****** Document ****** 594\n",
      " ****** Document ****** 595\n",
      "1.1  not in WE, adding it with random vector\n",
      " ****** Document ****** 596\n",
      " ****** Document ****** 597\n",
      " ****** Document ****** 598\n",
      " ****** Document ****** 599\n",
      " ****** Document ****** 600\n",
      "Bickwit  not in WE, adding it with random vector\n",
      " ****** Document ****** 601\n",
      " ****** Document ****** 602\n",
      "48,100  not in WE, adding it with random vector\n",
      " ****** Document ****** 603\n",
      " ****** Document ****** 604\n",
      " ****** Document ****** 605\n",
      " ****** Document ****** 606\n",
      " ****** Document ****** 607\n",
      " ****** Document ****** 608\n",
      " ****** Document ****** 609\n",
      "729  not in WE, adding it with random vector\n",
      " ****** Document ****** 610\n",
      "225  not in WE, adding it with random vector\n",
      " ****** Document ****** 611\n",
      "government-insured  not in WE, adding it with random vector\n",
      " ****** Document ****** 612\n",
      " ****** Document ****** 613\n",
      "bankruptcy-law  not in WE, adding it with random vector\n",
      " ****** Document ****** 614\n",
      " ****** Document ****** 615\n",
      " ****** Document ****** 616\n",
      " ****** Document ****** 617\n",
      "off-base  not in WE, adding it with random vector\n",
      " ****** Document ****** 618\n",
      " ****** Document ****** 619\n",
      " ****** Document ****** 620\n",
      " ****** Document ****** 621\n",
      " ****** Document ****** 622\n",
      " ****** Document ****** 623\n",
      "1.8  not in WE, adding it with random vector\n",
      " ****** Document ****** 624\n",
      " ****** Document ****** 625\n",
      " ****** Document ****** 626\n",
      " ****** Document ****** 627\n",
      "last-minute  not in WE, adding it with random vector\n",
      " ****** Document ****** 628\n",
      " ****** Document ****** 629\n",
      "scaled-down  not in WE, adding it with random vector\n",
      " ****** Document ****** 630\n",
      " ****** Document ****** 631\n",
      " ****** Document ****** 632\n",
      " ****** Document ****** 633\n",
      " ****** Document ****** 634\n",
      " ****** Document ****** 635\n",
      "120  not in WE, adding it with random vector\n",
      "135  not in WE, adding it with random vector\n",
      " ****** Document ****** 636\n",
      " ****** Document ****** 637\n",
      " ****** Document ****** 638\n",
      " ****** Document ****** 639\n",
      " ****** Document ****** 640\n",
      "775  not in WE, adding it with random vector\n",
      "700  not in WE, adding it with random vector\n",
      " ****** Document ****** 641\n",
      " ****** Document ****** 642\n",
      " ****** Document ****** 643\n",
      "390  not in WE, adding it with random vector\n",
      " ****** Document ****** 644\n",
      " ****** Document ****** 645\n",
      " ****** Document ****** 646\n",
      " ****** Document ****** 647\n",
      " ****** Document ****** 648\n",
      " ****** Document ****** 649\n",
      " ****** Document ****** 650\n",
      " ****** Document ****** 651\n",
      " ****** Document ****** 652\n",
      " ****** Document ****** 653\n",
      " ****** Document ****** 654\n",
      "90  not in WE, adding it with random vector\n",
      "pre-bankruptcy  not in WE, adding it with random vector\n",
      " ****** Document ****** 655\n",
      "1,000  not in WE, adding it with random vector\n",
      "1,050  not in WE, adding it with random vector\n",
      " ****** Document ****** 656\n",
      "SIMPLIFYING  not in WE, adding it with random vector\n",
      " ****** Document ****** 657\n",
      " ****** Document ****** 658\n",
      " ****** Document ****** 659\n",
      " ****** Document ****** 660\n",
      "stripped-down  not in WE, adding it with random vector\n",
      " ****** Document ****** 661\n",
      " ****** Document ****** 662\n",
      " ****** Document ****** 663\n",
      " ****** Document ****** 664\n",
      " ****** Document ****** 665\n",
      "RAVAGES  not in WE, adding it with random vector\n",
      " ****** Document ****** 666\n",
      "hurricane-wracked  not in WE, adding it with random vector\n",
      " ****** Document ****** 667\n",
      "16  not in WE, adding it with random vector\n",
      " ****** Document ****** 668\n",
      " ****** Document ****** 669\n",
      " ****** Document ****** 670\n",
      " ****** Document ****** 671\n",
      " ****** Document ****** 672\n",
      "six-month  not in WE, adding it with random vector\n",
      " ****** Document ****** 673\n",
      "late-payment  not in WE, adding it with random vector\n",
      " ****** Document ****** 674\n",
      "89-136  not in WE, adding it with random vector\n",
      " ****** Document ****** 675\n",
      "Fiscal-year  not in WE, adding it with random vector\n",
      " ****** Document ****** 676\n",
      "Excise-tax  not in WE, adding it with random vector\n",
      " ****** Document ****** 677\n",
      "employment-tax  not in WE, adding it with random vector\n",
      " ****** Document ****** 678\n",
      "estate-tax  not in WE, adding it with random vector\n",
      " ****** Document ****** 679\n",
      "ONE-DAY  not in WE, adding it with random vector\n",
      "JAUNTS  not in WE, adding it with random vector\n",
      " ****** Document ****** 680\n",
      " ****** Document ****** 681\n",
      " ****** Document ****** 682\n",
      "USED-CAR  not in WE, adding it with random vector\n",
      " ****** Document ****** 683\n",
      " ****** Document ****** 684\n",
      "5498  not in WE, adding it with random vector\n",
      " ****** Document ****** 685\n",
      "89-52  not in WE, adding it with random vector\n",
      " ****** Document ****** 686\n",
      "BREADBOX  not in WE, adding it with random vector\n",
      " ****** Document ****** 687\n",
      " ****** Document ****** 688\n",
      "Damonne  not in WE, adding it with random vector\n",
      " ****** Document ****** 689\n",
      "124,732  not in WE, adding it with random vector\n",
      "1982-84  not in WE, adding it with random vector\n",
      "52,012  not in WE, adding it with random vector\n",
      " ****** Document ****** 690\n",
      " ****** Document ****** 691\n",
      "47,000  not in WE, adding it with random vector\n",
      "1974-81  not in WE, adding it with random vector\n",
      "45,000  not in WE, adding it with random vector\n",
      "1955  not in WE, adding it with random vector\n",
      " ****** Document ****** 692\n",
      "ex-employer  not in WE, adding it with random vector\n",
      " ****** Document ****** 693\n",
      " ****** Document ****** 694\n",
      " ****** Document ****** 695\n",
      "26,350  not in WE, adding it with random vector\n",
      "two-year  not in WE, adding it with random vector\n",
      "46,892  not in WE, adding it with random vector\n",
      " ****** Document ****** 696\n",
      " ****** Document ****** 697\n",
      " ****** Document ****** 698\n",
      " ****** Document ****** 699\n",
      "picture-postcard  not in WE, adding it with random vector\n",
      "Indian-summer  not in WE, adding it with random vector\n",
      " ****** Document ****** 700\n",
      "day-long  not in WE, adding it with random vector\n",
      "fat-tired  not in WE, adding it with random vector\n",
      " ****** Document ****** 701\n",
      " ****** Document ****** 702\n",
      " ****** Document ****** 703\n",
      " ****** Document ****** 704\n",
      " ****** Document ****** 705\n",
      " ****** Document ****** 706\n",
      " ****** Document ****** 707\n",
      " ****** Document ****** 708\n",
      "65,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 709\n",
      " ****** Document ****** 710\n",
      " ****** Document ****** 711\n",
      "all-terrain  not in WE, adding it with random vector\n",
      " ****** Document ****** 712\n",
      "fitness-promoting  not in WE, adding it with random vector\n",
      " ****** Document ****** 713\n",
      " ****** Document ****** 714\n",
      " ****** Document ****** 715\n",
      " ****** Document ****** 716\n",
      "40  not in WE, adding it with random vector\n",
      " ****** Document ****** 717\n",
      "public-land  not in WE, adding it with random vector\n",
      " ****** Document ****** 718\n",
      " ****** Document ****** 719\n",
      " ****** Document ****** 720\n",
      " ****** Document ****** 721\n",
      " ****** Document ****** 722\n",
      "multiple-use  not in WE, adding it with random vector\n",
      " ****** Document ****** 723\n",
      "anti-bike  not in WE, adding it with random vector\n",
      " ****** Document ****** 724\n",
      " ****** Document ****** 725\n",
      "all-out  not in WE, adding it with random vector\n",
      " ****** Document ****** 726\n",
      "hard-line  not in WE, adding it with random vector\n",
      "500,000  not in WE, adding it with random vector\n",
      " ****** Document ****** 727\n",
      "terrain-marring  not in WE, adding it with random vector\n",
      "off-road  not in WE, adding it with random vector\n",
      " ****** Document ****** 728\n",
      " ****** Document ****** 729\n",
      " ****** Document ****** 730\n",
      " ****** Document ****** 731\n",
      " ****** Document ****** 732\n",
      " ****** Document ****** 733\n",
      " ****** Document ****** 734\n",
      "Off-Road  not in WE, adding it with random vector\n",
      " ****** Document ****** 735\n",
      " ****** Document ****** 736\n",
      "Francisco-area  not in WE, adding it with random vector\n",
      " ****** Document ****** 737\n",
      " ****** Document ****** 738\n",
      " ****** Document ****** 739\n",
      " ****** Document ****** 740\n",
      "multi-gear  not in WE, adding it with random vector\n",
      " ****** Document ****** 741\n",
      " ****** Document ****** 742\n",
      "thin-tired  not in WE, adding it with random vector\n",
      " ****** Document ****** 743\n",
      "1981  not in WE, adding it with random vector\n",
      " ****** Document ****** 744\n",
      " ****** Document ****** 745\n",
      " ****** Document ****** 746\n",
      " ****** Document ****** 747\n",
      " ****** Document ****** 748\n",
      "1,200  not in WE, adding it with random vector\n",
      " ****** Document ****** 749\n",
      " ****** Document ****** 750\n",
      " ****** Document ****** 751\n",
      " ****** Document ****** 752\n",
      " ****** Document ****** 753\n",
      " ****** Document ****** 754\n",
      " ****** Document ****** 755\n",
      "550  not in WE, adding it with random vector\n",
      " ****** Document ****** 756\n",
      "Gotaas-Larsen  not in WE, adding it with random vector\n",
      "280  not in WE, adding it with random vector\n",
      " ****** Document ****** 757\n",
      "H.F.  not in WE, adding it with random vector\n",
      " ****** Document ****** 758\n",
      " ****** Document ****** 759\n",
      "Stock-market  not in WE, adding it with random vector\n",
      " ****** Document ****** 760\n",
      " ****** Document ****** 761\n",
      " ****** Document ****** 762\n",
      " ****** Document ****** 763\n",
      "60.25  not in WE, adding it with random vector\n",
      "18.65  not in WE, adding it with random vector\n",
      "2638.73  not in WE, adding it with random vector\n",
      " ****** Document ****** 764\n",
      "Long-term  not in WE, adding it with random vector\n",
      " ****** Document ****** 765\n",
      " ****** Document ****** 766\n",
      " ****** Document ****** 767\n",
      " ****** Document ****** 768\n",
      "10.77  not in WE, adding it with random vector\n",
      " ****** Document ****** 769\n",
      " ****** Document ****** 770\n",
      " ****** Document ****** 771\n",
      " ****** Document ****** 772\n",
      " ****** Document ****** 773\n",
      " ****** Document ****** 774\n",
      "one-quarter  not in WE, adding it with random vector\n",
      " ****** Document ****** 775\n",
      " ****** Document ****** 776\n",
      " ****** Document ****** 777\n",
      " ****** Document ****** 778\n",
      "corporate-earnings  not in WE, adding it with random vector\n",
      " ****** Document ****** 779\n",
      "junk-bond  not in WE, adding it with random vector\n",
      " ****** Document ****** 780\n",
      " ****** Document ****** 781\n",
      " ****** Document ****** 782\n",
      "30-year  not in WE, adding it with random vector\n",
      "8.03  not in WE, adding it with random vector\n",
      " ****** Document ****** 783\n",
      " ****** Document ****** 784\n",
      "142.75  not in WE, adding it with random vector\n",
      "141.80  not in WE, adding it with random vector\n",
      "1.8667  not in WE, adding it with random vector\n",
      "1.8685  not in WE, adding it with random vector\n",
      " ****** Document ****** 785\n",
      " ****** Document ****** 786\n",
      " ****** Document ****** 787\n",
      " ****** Document ****** 788\n",
      " ****** Document ****** 789\n",
      " ****** Document ****** 790\n",
      " ****** Document ****** 791\n",
      " ****** Document ****** 792\n",
      " ****** Document ****** 793\n",
      " ****** Document ****** 794\n",
      "!  not in WE, adding it with random vector\n",
      " ****** Document ****** 795\n",
      "Ludcke  not in WE, adding it with random vector\n",
      " ****** Document ****** 796\n",
      " ****** Document ****** 797\n",
      " ****** Document ****** 798\n",
      "Kafaroff  not in WE, adding it with random vector\n",
      " ****** Document ****** 799\n",
      "Daffynition  not in WE, adding it with random vector\n",
      " ****** Document ****** 800\n",
      " ****** Document ****** 801\n",
      " ****** Document ****** 802\n",
      "one-time  not in WE, adding it with random vector\n",
      "wood-product  not in WE, adding it with random vector\n",
      "166.8  not in WE, adding it with random vector\n",
      "78  not in WE, adding it with random vector\n",
      " ****** Document ****** 803\n",
      "forest-products  not in WE, adding it with random vector\n",
      "144.9  not in WE, adding it with random vector\n",
      " ****** Document ****** 804\n",
      "2.57  not in WE, adding it with random vector\n",
      "2.36  not in WE, adding it with random vector\n",
      " ****** Document ****** 805\n",
      "469.8  not in WE, adding it with random vector\n",
      "2.21  not in WE, adding it with random vector\n",
      "410.3  not in WE, adding it with random vector\n",
      "1.95  not in WE, adding it with random vector\n",
      " ****** Document ****** 806\n",
      "7.54  not in WE, adding it with random vector\n",
      "6.95  not in WE, adding it with random vector\n",
      " ****** Document ****** 807\n",
      " ****** Document ****** 808\n",
      "Forest-products  not in WE, adding it with random vector\n",
      " ****** Document ****** 809\n",
      " ****** Document ****** 810\n",
      "full-year  not in WE, adding it with random vector\n",
      " ****** Document ****** 811\n",
      " ****** Document ****** 812\n",
      " ****** Document ****** 813\n",
      "less-developed  not in WE, adding it with random vector\n",
      "1.6  not in WE, adding it with random vector\n",
      " ****** Document ****** 814\n",
      "1.42  not in WE, adding it with random vector\n",
      " ****** Document ****** 815\n",
      "2.6  not in WE, adding it with random vector\n",
      "long-term  not in WE, adding it with random vector\n",
      " ****** Document ****** 816\n",
      " ****** Document ****** 817\n",
      " ****** Document ****** 818\n",
      " ****** Document ****** 819\n",
      " ****** Document ****** 820\n",
      "789  not in WE, adding it with random vector\n",
      "950  not in WE, adding it with random vector\n",
      " ****** Document ****** 821\n",
      " ****** Document ****** 822\n",
      " ****** Document ****** 823\n",
      "9.8  not in WE, adding it with random vector\n",
      "3.8  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 824\n",
      "near-record  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 825\n",
      " ****** TEST Document ****** 826\n",
      " ****** TEST Document ****** 827\n",
      " ****** TEST Document ****** 828\n",
      " ****** TEST Document ****** 829\n",
      " ****** TEST Document ****** 830\n",
      "3.2  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 831\n",
      "2.2  not in WE, adding it with random vector\n",
      "2.3  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 832\n",
      " ****** TEST Document ****** 833\n",
      " ****** TEST Document ****** 834\n",
      " ****** TEST Document ****** 835\n",
      " ****** TEST Document ****** 836\n",
      " ****** TEST Document ****** 837\n",
      " ****** TEST Document ****** 838\n",
      " ****** TEST Document ****** 839\n",
      " ****** TEST Document ****** 840\n",
      " ****** TEST Document ****** 841\n",
      " ****** TEST Document ****** 842\n",
      " ****** TEST Document ****** 843\n",
      " ****** TEST Document ****** 844\n",
      "5.4  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 845\n",
      " ****** TEST Document ****** 846\n",
      " ****** TEST Document ****** 847\n",
      " ****** TEST Document ****** 848\n",
      " ****** TEST Document ****** 849\n",
      " ****** TEST Document ****** 850\n",
      " ****** TEST Document ****** 851\n",
      "1.5890  not in WE, adding it with random vector\n",
      "2.9495  not in WE, adding it with random vector\n",
      "1.5940  not in WE, adding it with random vector\n",
      "2.9429  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 852\n",
      "2.90  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 853\n",
      " ****** TEST Document ****** 854\n",
      " ****** TEST Document ****** 855\n",
      "13  not in WE, adding it with random vector\n",
      "190  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 856\n",
      " ****** TEST Document ****** 857\n",
      "1.8578  not in WE, adding it with random vector\n",
      "1.8470  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 858\n",
      "142.43  not in WE, adding it with random vector\n",
      "141.70  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 859\n",
      "141.95  not in WE, adding it with random vector\n",
      "141.35  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 860\n",
      "367.30  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 861\n",
      "2.4  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 862\n",
      "366.50  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 863\n",
      " ****** TEST Document ****** 864\n",
      " ****** TEST Document ****** 865\n",
      " ****** TEST Document ****** 866\n",
      " ****** TEST Document ****** 867\n",
      "40-a-share  not in WE, adding it with random vector\n",
      "106.6  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 868\n",
      "2,664,098  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 869\n",
      "1.875  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 870\n",
      " ****** TEST Document ****** 871\n",
      "8.7  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 872\n",
      "233,000  not in WE, adding it with random vector\n",
      "30,000  not in WE, adding it with random vector\n",
      "35.50  not in WE, adding it with random vector\n",
      "36.50  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 873\n",
      "York-based  not in WE, adding it with random vector\n",
      "L.P  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 874\n",
      " ****** TEST Document ****** 875\n",
      " ****** TEST Document ****** 876\n",
      " ****** TEST Document ****** 877\n",
      "air-freight  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 878\n",
      " ****** TEST Document ****** 879\n",
      " ****** TEST Document ****** 880\n",
      " ****** TEST Document ****** 881\n",
      "freight-transport  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 882\n",
      " ****** TEST Document ****** 883\n",
      "broad-based  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 884\n",
      " ****** TEST Document ****** 885\n",
      " ****** TEST Document ****** 886\n",
      "inter-city  not in WE, adding it with random vector\n",
      "150  not in WE, adding it with random vector\n",
      "6.4  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 887\n",
      " ****** TEST Document ****** 888\n",
      " ****** TEST Document ****** 889\n",
      "transportation-cost  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 890\n",
      " ****** TEST Document ****** 891\n",
      "freight-cost  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 892\n",
      "freight-rate  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 893\n",
      " ****** TEST Document ****** 894\n",
      " ****** TEST Document ****** 895\n",
      " ****** TEST Document ****** 896\n",
      "Less-than-truckload  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 897\n",
      " ****** TEST Document ****** 898\n",
      "Railroad-rate  not in WE, adding it with random vector\n",
      "rail-traffic  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 899\n",
      "less-than-truckload  not in WE, adding it with random vector\n",
      " ****** TEST Document ****** 900\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=10) # seed the randomness\n",
    "\n",
    "dictadd = dict()\n",
    "cpt=0\n",
    "for d in alldocs:\n",
    "    cpt+=1\n",
    "    print(\" ****** Document ******\",cpt)\n",
    "    for (x,pos) in d:\n",
    "        if (not (x in wv_pre_trained) and not (x in dictadd)):\n",
    "            print(x,\" not in WE, adding it with random vector\")\n",
    "            dictadd[x] = randomvec()\n",
    "            \n",
    "for d in alldocsT:\n",
    "    cpt+=1\n",
    "    print(\" ****** TEST Document ******\",cpt)\n",
    "    for (x,pos) in d:\n",
    "        if (not (x in wv_pre_trained) and not (x in dictadd)):\n",
    "            print(x,\" not in WE, adding it with random vector\")\n",
    "            dictadd[x] = randomvec()\n",
    "#             wv_pre_trained.add_vector(x,randomvec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94cd47",
   "metadata": {},
   "source": [
    "### Add the (key-value) 'random' word embeddings for missing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b202e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "wv_pre_trained.add_vectors(list(dictadd.keys()),list(dictadd.values())) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5cb9f7",
   "metadata": {},
   "source": [
    "### Store the train and test datasets: a word embedding for each token in the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e1f1325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19172, 1896)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvectors  = []\n",
    "for doc in alldocs:\n",
    "    for token, tag in doc:\n",
    "        t_vec = wv_pre_trained[token]\n",
    "        wvectors.append(t_vec)\n",
    "    \n",
    "wvectorsT  = []\n",
    "for doc in alldocsT:\n",
    "    for token, tag in doc:\n",
    "        try:\n",
    "            t_vec = wv_pre_trained[token]\n",
    "            wvectorsT.append(t_vec)\n",
    "        except:\n",
    "            print(token)\n",
    "            pass\n",
    "    \n",
    "len(wvectors), len(wvectorsT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be97535",
   "metadata": {},
   "source": [
    "### Check the size of your train/test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ca328",
   "metadata": {},
   "source": [
    "### Collecting train/test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e2b7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42  keys in the dictionary\n",
      "43  keys in the dictionary\n"
     ]
    }
   ],
   "source": [
    "# Labels train/test\n",
    "\n",
    "buf2 = [[pos for m,pos in d ] for d in alldocs]\n",
    "cles = []\n",
    "[cles.extend(b) for b in buf2]\n",
    "cles = np.unique(np.array(cles))\n",
    "cles2ind = dict(zip(cles,range(len(cles))))\n",
    "nCles = len(cles)\n",
    "print(nCles,\" keys in the dictionary\")\n",
    "\n",
    "labels  = np.array([cles2ind[pos] for d in alldocs for (m,pos) in d ])\n",
    "#np.array([cles2ind[pos] for (m,pos) in d for d in alldocs])\n",
    "labelsT  = np.array([cles2ind.setdefault(pos,len(cles)) for d in alldocsT for (m,pos) in d ])\n",
    "\n",
    "print(len(cles2ind),\" keys in the dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "001760be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19172,)\n",
      "(1896,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(labelsT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5133930",
   "metadata": {},
   "source": [
    "### Train a Logistic Regression Model! \n",
    "**An compare performances to the baseline and sequence models (HMM/CRF) or practical 2a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b3c60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore DeprecationWarning\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd1c94ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.9243807  0.92125163 0.92018779 0.92749087 0.92357851]\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create a stratified cross-validation object\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the metrics for scoring\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "}\n",
    "\n",
    "# Perform cross-validation with different metrics for scoring\n",
    "cv_results = cross_validate(model, np.array(wvectors), labels, cv=cv, scoring=scoring)\n",
    "\n",
    "# Print test results\n",
    "print('Accuracy:', cv_results['test_accuracy'])\n",
    "# print('Precision:', cv_results['test_precision'])\n",
    "# print('Recall:', cv_results['test_recall'])\n",
    "# print('F1 score:', cv_results['test_f1'])\n",
    "# print('ROC AUC score:', cv_results['test_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1943498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(wvectors),labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eca1cfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129746835443038"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(np.array(wvectorsT), labelsT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0843e3c5",
   "metadata": {},
   "source": [
    "### HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5181b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allx: list of observation sequences \n",
    "# allq: list os state sequences \n",
    "# N: nb states\n",
    "# K: nb observations\n",
    "\n",
    "def learnHMM(allx, allq, N, K, initTo1=True):\n",
    "    \"\"\"\n",
    "    Computes the parameters of the hmm model to learn\n",
    "    \"\"\"\n",
    "    if initTo1:\n",
    "        eps = 1e-3 # You can play with this regularization parameter \n",
    "        A = np.ones((N,N))*eps\n",
    "        B = np.ones((N,K))*eps\n",
    "        Pi = np.ones(N)*eps\n",
    "    else:\n",
    "        A = np.zeros((N,N))\n",
    "        B = np.zeros((N,K))\n",
    "        Pi = np.zeros(N)\n",
    "    # Iterate over all sequences and their respective observations\n",
    "    for x,q in zip(allx,allq):\n",
    "        # Compute Pi vector based on first words proba\n",
    "        Pi[int(q[0])] += 1\n",
    "        for i in range(len(q)-1):\n",
    "            A[int(q[i]),int(q[i+1])] += 1\n",
    "            B[int(q[i]),int(x[i])] += 1\n",
    "        B[int(q[-1]),int(x[-1])] += 1 # last transition\n",
    "    A = A/np.maximum(A.sum(1).reshape(N,1),1) # normalisation\n",
    "    B = B/np.maximum(B.sum(1).reshape(N,1),1) # normalisation\n",
    "    Pi = Pi/Pi.sum()\n",
    "    return Pi , A, B\n",
    "\n",
    "def viterbi(x,Pi,A,B):\n",
    "    \"\"\"\n",
    "    Finds the state sequence that maximizes the likelihood of the observed sequence\n",
    "    \"\"\"\n",
    "    T = len(x)\n",
    "    N = len(Pi)\n",
    "    logA = np.log(A)\n",
    "    logB = np.log(B)\n",
    "    logdelta = np.zeros((N,T))\n",
    "    psi = np.zeros((N,T), dtype=int)\n",
    "    S = np.zeros(T)\n",
    "    logdelta[:,0] = np.log(Pi) + logB[:,int(x[0])]\n",
    "    #forward\n",
    "    for t in range(1,T):\n",
    "        logdelta[:,t] = (logdelta[:,t-1].reshape(N,1) + logA).max(0) + logB[:,int(x[t])]\n",
    "        psi[:,t] = (logdelta[:,t-1].reshape(N,1) + logA).argmax(0)\n",
    "    # backward\n",
    "    logp = logdelta[:,-1].max()\n",
    "    S[T-1] = logdelta[:,-1].argmax()\n",
    "    for i in range(2,T+1):\n",
    "        S[int(T-i)] = psi[int(S[int(T-i+1)]),int(T-i+1)]\n",
    "    return S, logp #, delta, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56003b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4570 17  in the dictionary\n"
     ]
    }
   ],
   "source": [
    "# alldocs etant issu du chargement des donnÃ©es\n",
    "# la mise en forme des donnÃ©es est fournie ici\n",
    "# afin de produire des analyses qualitative, vous devez malgrÃ© tout comprendre le fonctionnement des dictionnaires\n",
    "\n",
    "buf = [[m for m,pos in d ] for d in alldocs]\n",
    "mots = []\n",
    "[mots.extend(b) for b in buf]\n",
    "mots = np.unique(np.array(mots))\n",
    "nMots = len(mots)+1 # mot inconnu\n",
    "\n",
    "mots2ind = dict(zip(mots,range(len(mots))))\n",
    "mots2ind[\"UUUUUUUU\"] = len(mots)\n",
    "\n",
    "buf2 = [[pos for m,pos in d ] for d in alldocs]\n",
    "cles = []\n",
    "[cles.extend(b) for b in buf2]\n",
    "cles = np.unique(np.array(cles))\n",
    "cles2ind = dict(zip(cles,range(len(cles))))\n",
    "\n",
    "nCles = len(cles)\n",
    "\n",
    "print(nMots,nCles,\" in the dictionary\")\n",
    "\n",
    "# mise en forme des donnÃ©es\n",
    "allx  = [[mots2ind[m] for m,pos in d] for d in alldocs]\n",
    "allxT = [[mots2ind.setdefault(m,len(mots)) for m,pos in d] for d in alldocsT]\n",
    "\n",
    "allq  = [[cles2ind[pos] for m,pos in d] for d in alldocs]\n",
    "allqT = [[cles2ind.setdefault(pos,len(cles)) for m,pos in d] for d in alldocsT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c2cd041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi , A, B = learnHMM(allx, allq, nCles, nMots, initTo1=True)\n",
    "seq, log_probs = [],[]\n",
    "for d in allx:\n",
    "    s,p = viterbi(d,pi, A, B)\n",
    "    seq.append(s)\n",
    "    log_probs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f940d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HMM decoding and performances evaluation\n",
    "# Evaluate test performances\n",
    "cpt=0\n",
    "pred = 0\n",
    "y_hat,y = [],[]\n",
    "for doc,state in zip(allxT,allqT) :\n",
    "    for p_pred, p_real in zip(viterbi(doc,pi,A,B)[0],state):\n",
    "        if p_pred == p_real :\n",
    "            y_hat.append(p_pred)\n",
    "            y.append(p_real)\n",
    "            cpt+=1\n",
    "            \n",
    "accuracy_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba892e1",
   "metadata": {},
   "source": [
    "## CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "542c8c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071729957805907"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install python-crfsuite\n",
    "import nltk\n",
    "from nltk.tag.crf import CRFTagger\n",
    "tagger = CRFTagger()\n",
    "tagger.train(alldocs, './out/crf.model') # training\n",
    "tagger.evaluate(alldocsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "094a7fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161392405063291"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perceptron\n",
    "from nltk.tag.perceptron    import PerceptronTagger\n",
    "tagger = PerceptronTagger(load=False)\n",
    "tagger.train(alldocs)\n",
    "tagger.evaluate(alldocsT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fbd43a",
   "metadata": {},
   "source": [
    "# 2) Using word embedding with CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6ce24",
   "metadata": {},
   "source": [
    "## We will define the following features functions for CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3668c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_wv(sentence, index):\n",
    "    \"\"\"\n",
    "        This function encodes the pre-trained word vectors for each word in the sentence \n",
    "        using a pre-trained word embedding model. \n",
    "        The function takes in a sentence and an index, and returns a dictionary of 300 features,\n",
    "        where each feature corresponds to a dimension in the word vector.\n",
    "    \"\"\"\n",
    "    v = wv_pre_trained.get_vector(sentence[index])\n",
    "    d = {'f'+str(i):v[i] for i in range(300)}\n",
    "    return d\n",
    "\n",
    "def features_structural(sentence, index):\n",
    "    \"\"\"\n",
    "    This function encodes various structural features of each word in the sentence, \n",
    "    such as its position in the sentence, whether it is capitalized, whether it \n",
    "    contains a hyphen, etc. \n",
    "    The function takes in a sentence and an index, and returns a dictionary of 16 features.\n",
    "\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "     ## We will define the following features functions for CRF## We will define the following features functions for CRF   'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    "def features_wv_plus_structural(sentence, index):\n",
    "    \"\"\"\n",
    "    This function combines the features from the previous two functions. \n",
    "    It encodes both the pre-trained word vectors and the structural features \n",
    "    for each word in the sentence. \n",
    "    The function takes in a sentence and an index, and returns a dictionary \n",
    "    of 316 features (300 from word vectors + 16 from structural features).\n",
    "    \"\"\"\n",
    "    v = wv_pre_trained.get_vector(sentence[index]) \n",
    "    d = {'f'+str(i):v[i] for i in range(300)}\n",
    "\n",
    "    return {**d, **features_structural(sentence, index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f3fb9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f0': -0.10595703,\n",
       " 'f1': 0.00029945374,\n",
       " 'f2': 0.041503906,\n",
       " 'f3': -0.014404297,\n",
       " 'f4': -0.16015625,\n",
       " 'f5': 0.103515625,\n",
       " 'f6': 0.007385254,\n",
       " 'f7': -0.06201172,\n",
       " 'f8': 0.18945312,\n",
       " 'f9': -0.106933594,\n",
       " 'f10': 0.1484375,\n",
       " 'f11': -0.14941406,\n",
       " 'f12': 0.00042915344,\n",
       " 'f13': -0.27539062,\n",
       " 'f14': -0.17578125,\n",
       " 'f15': 0.016845703,\n",
       " 'f16': -0.083496094,\n",
       " 'f17': -0.3125,\n",
       " 'f18': -0.109375,\n",
       " 'f19': -0.076660156,\n",
       " 'f20': -0.021362305,\n",
       " 'f21': -0.20703125,\n",
       " 'f22': -0.12597656,\n",
       " 'f23': -0.07910156,\n",
       " 'f24': 0.0077209473,\n",
       " 'f25': -0.1015625,\n",
       " 'f26': -0.20898438,\n",
       " 'f27': 0.087402344,\n",
       " 'f28': -0.27539062,\n",
       " 'f29': 0.015136719,\n",
       " 'f30': 0.068847656,\n",
       " 'f31': -0.13574219,\n",
       " 'f32': -0.14941406,\n",
       " 'f33': 0.030151367,\n",
       " 'f34': 0.056152344,\n",
       " 'f35': 0.072265625,\n",
       " 'f36': 0.02331543,\n",
       " 'f37': -0.08886719,\n",
       " 'f38': -0.018310547,\n",
       " 'f39': 0.103515625,\n",
       " 'f40': 0.011657715,\n",
       " 'f41': -0.19042969,\n",
       " 'f42': -0.033447266,\n",
       " 'f43': 0.19824219,\n",
       " 'f44': -0.09326172,\n",
       " 'f45': -0.21875,\n",
       " 'f46': 0.060546875,\n",
       " 'f47': 0.040283203,\n",
       " 'f48': 0.14453125,\n",
       " 'f49': 0.03100586,\n",
       " 'f50': 0.19921875,\n",
       " 'f51': 0.00074768066,\n",
       " 'f52': 0.1328125,\n",
       " 'f53': 0.14746094,\n",
       " 'f54': 0.037597656,\n",
       " 'f55': -0.21289062,\n",
       " 'f56': -0.10644531,\n",
       " 'f57': 0.08544922,\n",
       " 'f58': 0.044433594,\n",
       " 'f59': -0.09423828,\n",
       " 'f60': -0.03955078,\n",
       " 'f61': 0.36523438,\n",
       " 'f62': -0.18554688,\n",
       " 'f63': -0.016845703,\n",
       " 'f64': 0.057617188,\n",
       " 'f65': -0.05883789,\n",
       " 'f66': -0.059326172,\n",
       " 'f67': -0.23046875,\n",
       " 'f68': -0.09863281,\n",
       " 'f69': 0.07910156,\n",
       " 'f70': 0.115234375,\n",
       " 'f71': 0.071777344,\n",
       " 'f72': 0.020874023,\n",
       " 'f73': 0.043701172,\n",
       " 'f74': -0.04711914,\n",
       " 'f75': -0.05834961,\n",
       " 'f76': 0.11425781,\n",
       " 'f77': -0.083984375,\n",
       " 'f78': 0.12451172,\n",
       " 'f79': -0.22558594,\n",
       " 'f80': 0.17871094,\n",
       " 'f81': 0.104003906,\n",
       " 'f82': 0.140625,\n",
       " 'f83': 0.2578125,\n",
       " 'f84': 0.055419922,\n",
       " 'f85': 0.018310547,\n",
       " 'f86': -0.10107422,\n",
       " 'f87': 0.1875,\n",
       " 'f88': 0.019165039,\n",
       " 'f89': 0.109375,\n",
       " 'f90': 0.2109375,\n",
       " 'f91': 0.037841797,\n",
       " 'f92': 0.06591797,\n",
       " 'f93': -0.026245117,\n",
       " 'f94': 0.030639648,\n",
       " 'f95': 0.17773438,\n",
       " 'f96': -0.0859375,\n",
       " 'f97': -0.1953125,\n",
       " 'f98': 0.16015625,\n",
       " 'f99': -0.06542969,\n",
       " 'f100': 0.36914062,\n",
       " 'f101': -0.068359375,\n",
       " 'f102': -0.07373047,\n",
       " 'f103': 0.04736328,\n",
       " 'f104': 0.19042969,\n",
       " 'f105': -0.13769531,\n",
       " 'f106': 0.021118164,\n",
       " 'f107': 0.20703125,\n",
       " 'f108': 0.06640625,\n",
       " 'f109': -0.030395508,\n",
       " 'f110': -0.029541016,\n",
       " 'f111': -0.23242188,\n",
       " 'f112': -0.03466797,\n",
       " 'f113': -0.11816406,\n",
       " 'f114': 0.09814453,\n",
       " 'f115': 0.24902344,\n",
       " 'f116': -0.09863281,\n",
       " 'f117': 0.010986328,\n",
       " 'f118': 0.04321289,\n",
       " 'f119': -0.036621094,\n",
       " 'f120': -0.19238281,\n",
       " 'f121': -0.24707031,\n",
       " 'f122': -0.114746094,\n",
       " 'f123': 0.13964844,\n",
       " 'f124': -0.06298828,\n",
       " 'f125': -0.029907227,\n",
       " 'f126': -0.004699707,\n",
       " 'f127': -0.15625,\n",
       " 'f128': 0.36523438,\n",
       " 'f129': 0.20507812,\n",
       " 'f130': 0.24707031,\n",
       " 'f131': -0.13574219,\n",
       " 'f132': -0.07470703,\n",
       " 'f133': -0.083496094,\n",
       " 'f134': 0.06933594,\n",
       " 'f135': 0.057861328,\n",
       " 'f136': 0.07128906,\n",
       " 'f137': -0.038085938,\n",
       " 'f138': -0.21875,\n",
       " 'f139': -0.07763672,\n",
       " 'f140': 0.12207031,\n",
       " 'f141': -0.11035156,\n",
       " 'f142': 0.21191406,\n",
       " 'f143': 0.3046875,\n",
       " 'f144': -0.140625,\n",
       " 'f145': -0.19042969,\n",
       " 'f146': 0.21289062,\n",
       " 'f147': -0.07128906,\n",
       " 'f148': -0.18652344,\n",
       " 'f149': -0.031982422,\n",
       " 'f150': 0.17871094,\n",
       " 'f151': 0.14160156,\n",
       " 'f152': 0.048095703,\n",
       " 'f153': 0.33007812,\n",
       " 'f154': 0.033935547,\n",
       " 'f155': -0.050048828,\n",
       " 'f156': -0.13476562,\n",
       " 'f157': 0.12792969,\n",
       " 'f158': 0.07373047,\n",
       " 'f159': 0.11035156,\n",
       " 'f160': 0.25976562,\n",
       " 'f161': 0.20898438,\n",
       " 'f162': 0.091796875,\n",
       " 'f163': -0.15917969,\n",
       " 'f164': -0.07470703,\n",
       " 'f165': -0.048095703,\n",
       " 'f166': 0.032470703,\n",
       " 'f167': -0.05859375,\n",
       " 'f168': 0.12792969,\n",
       " 'f169': 0.013671875,\n",
       " 'f170': -0.10058594,\n",
       " 'f171': -0.33007812,\n",
       " 'f172': -0.099121094,\n",
       " 'f173': -0.29296875,\n",
       " 'f174': 0.0146484375,\n",
       " 'f175': -0.11230469,\n",
       " 'f176': 0.27929688,\n",
       " 'f177': 0.06225586,\n",
       " 'f178': -0.080078125,\n",
       " 'f179': 0.049316406,\n",
       " 'f180': 0.06933594,\n",
       " 'f181': -0.09814453,\n",
       " 'f182': -0.07714844,\n",
       " 'f183': 0.33398438,\n",
       " 'f184': -0.068359375,\n",
       " 'f185': -0.040527344,\n",
       " 'f186': 0.1640625,\n",
       " 'f187': 0.12792969,\n",
       " 'f188': -0.041992188,\n",
       " 'f189': 0.07128906,\n",
       " 'f190': 0.008422852,\n",
       " 'f191': -0.106933594,\n",
       " 'f192': 0.00592041,\n",
       " 'f193': 0.02722168,\n",
       " 'f194': -0.08935547,\n",
       " 'f195': -0.037353516,\n",
       " 'f196': -0.05810547,\n",
       " 'f197': 0.047851562,\n",
       " 'f198': 0.125,\n",
       " 'f199': 0.013000488,\n",
       " 'f200': -0.030517578,\n",
       " 'f201': 0.0062561035,\n",
       " 'f202': 0.013244629,\n",
       " 'f203': 0.059570312,\n",
       " 'f204': 0.025268555,\n",
       " 'f205': -0.060791016,\n",
       " 'f206': 0.091308594,\n",
       " 'f207': 0.09667969,\n",
       " 'f208': 0.14257812,\n",
       " 'f209': -0.18945312,\n",
       " 'f210': 0.06298828,\n",
       " 'f211': -0.017211914,\n",
       " 'f212': -0.20019531,\n",
       " 'f213': 0.15917969,\n",
       " 'f214': 0.08984375,\n",
       " 'f215': 0.13183594,\n",
       " 'f216': 0.21191406,\n",
       " 'f217': -0.05419922,\n",
       " 'f218': -0.34570312,\n",
       " 'f219': 0.043945312,\n",
       " 'f220': -0.08496094,\n",
       " 'f221': 0.25,\n",
       " 'f222': -0.12890625,\n",
       " 'f223': -0.0034637451,\n",
       " 'f224': -0.31835938,\n",
       " 'f225': -0.026489258,\n",
       " 'f226': -0.115722656,\n",
       " 'f227': 0.04638672,\n",
       " 'f228': 0.13574219,\n",
       " 'f229': -0.106933594,\n",
       " 'f230': -0.20117188,\n",
       " 'f231': -0.033935547,\n",
       " 'f232': -0.13671875,\n",
       " 'f233': -0.17089844,\n",
       " 'f234': -0.064453125,\n",
       " 'f235': 0.04248047,\n",
       " 'f236': -0.27148438,\n",
       " 'f237': 0.022949219,\n",
       " 'f238': -0.04736328,\n",
       " 'f239': 0.024291992,\n",
       " 'f240': 0.15332031,\n",
       " 'f241': -0.0138549805,\n",
       " 'f242': 0.03515625,\n",
       " 'f243': 0.16796875,\n",
       " 'f244': 0.080078125,\n",
       " 'f245': 0.12109375,\n",
       " 'f246': -0.16210938,\n",
       " 'f247': -0.038330078,\n",
       " 'f248': 0.05102539,\n",
       " 'f249': 0.050048828,\n",
       " 'f250': -0.013549805,\n",
       " 'f251': -0.091796875,\n",
       " 'f252': 0.0013580322,\n",
       " 'f253': 0.018066406,\n",
       " 'f254': 0.04711914,\n",
       " 'f255': -0.012023926,\n",
       " 'f256': 0.048095703,\n",
       " 'f257': 0.00970459,\n",
       " 'f258': 0.059814453,\n",
       " 'f259': -0.05444336,\n",
       " 'f260': 0.08935547,\n",
       " 'f261': -0.14550781,\n",
       " 'f262': -0.078125,\n",
       " 'f263': 0.14648438,\n",
       " 'f264': 0.12597656,\n",
       " 'f265': -0.0035705566,\n",
       " 'f266': 0.10253906,\n",
       " 'f267': -0.23144531,\n",
       " 'f268': -0.2734375,\n",
       " 'f269': 0.23339844,\n",
       " 'f270': 0.0390625,\n",
       " 'f271': -0.22363281,\n",
       " 'f272': 0.06542969,\n",
       " 'f273': -0.1328125,\n",
       " 'f274': 0.22753906,\n",
       " 'f275': -0.037841797,\n",
       " 'f276': 0.12011719,\n",
       " 'f277': -0.12011719,\n",
       " 'f278': -0.30859375,\n",
       " 'f279': -0.10644531,\n",
       " 'f280': -0.15039062,\n",
       " 'f281': -0.15039062,\n",
       " 'f282': 0.2265625,\n",
       " 'f283': 0.067871094,\n",
       " 'f284': 0.07910156,\n",
       " 'f285': 0.033203125,\n",
       " 'f286': 0.14355469,\n",
       " 'f287': 0.05517578,\n",
       " 'f288': 0.1796875,\n",
       " 'f289': 0.0050964355,\n",
       " 'f290': -0.06689453,\n",
       " 'f291': -0.029907227,\n",
       " 'f292': -0.19238281,\n",
       " 'f293': 0.18066406,\n",
       " 'f294': -0.1640625,\n",
       " 'f295': -0.06982422,\n",
       " 'f296': -0.13574219,\n",
       " 'f297': -0.18066406,\n",
       " 'f298': -0.063964844,\n",
       " 'f299': 0.049072266,\n",
       " 'word': 'unit',\n",
       " 'is_first': False,\n",
       " 'is_last': False,\n",
       " 'is_capitalized': False,\n",
       " 'is_all_caps': False,\n",
       " 'is_all_lower': True,\n",
       " 'prefix-1': 'u',\n",
       " 'prefix-2': 'un',\n",
       " 'prefix-3': 'uni',\n",
       " 'suffix-1': 't',\n",
       " 'suffix-2': 'it',\n",
       " 'suffix-3': 'nit',\n",
       " 'prev_word': 'Tulsa',\n",
       " 'next_word': 'said',\n",
       " 'has_hyphen': False,\n",
       " 'is_numeric': False}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_wv(alldocs[0], 0)\n",
    "\n",
    "sentence = ' '.join(str(elem) for elem, tag in alldocs[0])\n",
    "print(sentence.split()[5])\n",
    "features_wv_plus_structural(sentence.split(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38a9f9",
   "metadata": {},
   "source": [
    "## [Question]: explain what the 3 feature functions encode and what their differences are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56629f",
   "metadata": {},
   "source": [
    "The three feature functions encode different types of information about each word in a sentence:\n",
    "\n",
    "1. **features_wv(sentence, index):** This function encodes the pre-trained word vectors for each word in the sentence using a pre-trained word embedding model. The function takes in a sentence and an index, and returns a dictionary of 300 features, where each feature corresponds to a dimension in the word vector.\n",
    "\n",
    "2. **features_structural(sentence, index):** This function encodes various structural features of each word in the sentence, such as its position in the sentence, whether it is capitalized, whether it contains a hyphen, etc. The function takes in a sentence and an index, and returns a dictionary of 16 features.\n",
    "\n",
    "3. **features_wv_plus_structural(sentence, index):** This function combines the features from the previous two functions. It encodes both the pre-trained word vectors and the structural features for each word in the sentence. The function takes in a sentence and an index, and returns a dictionary of 316 features (300 from word vectors + 16 from structural features).\n",
    "\n",
    "**The main difference** between the three feature functions is the type of information they encode. The first function encodes semantic information about each word, the second encodes syntactic and structural information, and the third combines both semantic and structural information. These different types of information can be useful for different types of natural language processing tasks. For example, the semantic information encoded by the first function might be useful for tasks like word similarity or document classification, while the structural information encoded by the second function might be useful for tasks like part-of-speech tagging or named entity recognition. The third function combines both types of information, which might be useful for tasks that require both semantic and structural information, such as semantic role labeling or coreference resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6a31f",
   "metadata": {},
   "source": [
    "### You can now train a CRF with the 3 features and analyse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1fdc28",
   "metadata": {},
   "source": [
    "**feature_func:** \n",
    "\n",
    "The function that extracts features for each token of a sentence. This function should take\n",
    "            2 parameters: tokens and index which extract features at index position from tokens list. See the build in\n",
    "            _get_features function for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "410bb599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140295358649789"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature func 1\n",
    "\n",
    "import nltk\n",
    "from nltk.tag.crf import CRFTagger\n",
    "tagger = CRFTagger(feature_func=features_wv)\n",
    "tagger.train(alldocs, './out/crf_f1.model') # training\n",
    "tagger.evaluate(alldocsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3fbe8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929324894514768"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature func 2\n",
    "\n",
    "import nltk\n",
    "from nltk.tag.crf import CRFTagger\n",
    "tagger = CRFTagger(feature_func=features_structural)\n",
    "tagger.train(alldocs, './out/crf_f2.model') # training\n",
    "tagger.evaluate(alldocsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature func 3\n",
    "\n",
    "import nltk\n",
    "from nltk.tag.crf import CRFTagger\n",
    "tagger = CRFTagger(feature_func=features_wv_plus_structural)\n",
    "tagger.train(alldocs, './out/crf_f3.model') # training\n",
    "tagger.evaluate(alldocsT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
